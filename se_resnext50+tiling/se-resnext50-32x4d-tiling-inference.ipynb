{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "# for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "#     for filename in filenames:\n",
    "#         print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Imports\n",
    "from torch.utils.data import Dataset\n",
    "import cv2\n",
    "import openslide\n",
    "from skimage import io\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import cohen_kappa_score\n",
    "# from tqdm.notebook import tqdm\n",
    "from tqdm.notebook import trange, tqdm\n",
    "import time\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "\n",
    "from albumentations import Compose, Normalize, HorizontalFlip, VerticalFlip\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Load into Pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_id</th>\n",
       "      <th>data_provider</th>\n",
       "      <th>isup_grade</th>\n",
       "      <th>gleason_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0005f7aaab2800f6170c399693a96917</td>\n",
       "      <td>karolinska</td>\n",
       "      <td>0</td>\n",
       "      <td>0+0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>000920ad0b612851f8e01bcc880d9b3d</td>\n",
       "      <td>karolinska</td>\n",
       "      <td>0</td>\n",
       "      <td>0+0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0018ae58b01bdadc8e347995b69f99aa</td>\n",
       "      <td>radboud</td>\n",
       "      <td>4</td>\n",
       "      <td>4+4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>001c62abd11fa4b57bf7a6c603a11bb9</td>\n",
       "      <td>karolinska</td>\n",
       "      <td>4</td>\n",
       "      <td>4+4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>001d865e65ef5d2579c190a0e0350d8f</td>\n",
       "      <td>karolinska</td>\n",
       "      <td>0</td>\n",
       "      <td>0+0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           image_id data_provider  isup_grade gleason_score\n",
       "0  0005f7aaab2800f6170c399693a96917    karolinska           0           0+0\n",
       "1  000920ad0b612851f8e01bcc880d9b3d    karolinska           0           0+0\n",
       "2  0018ae58b01bdadc8e347995b69f99aa       radboud           4           4+4\n",
       "3  001c62abd11fa4b57bf7a6c603a11bb9    karolinska           4           4+4\n",
       "4  001d865e65ef5d2579c190a0e0350d8f    karolinska           0           0+0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = pd.read_csv('/kaggle/input/prostate-cancer-grade-assessment/train.csv')\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Tiling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_tiles(I, tile_size = 128, r_offset = 0, c_offset = 0, n = 12, ipr = 4):\n",
    "    \"\"\"\n",
    "    Params:\n",
    "        tile_size: n x n pixels per tile\n",
    "        r_offset: tiling starts n pixels left of input image left edge\n",
    "        c_offset: tiling: starts n pixels above input image top edge\n",
    "        n: total number of tiles in final stitched image\n",
    "        ipr: images per row in final stitched image\n",
    "    Returns:\n",
    "        final stitched image\n",
    "    \"\"\"\n",
    "\n",
    "    img = I[-1]\n",
    "    r, c, d = np.shape(img)\n",
    "\n",
    "\n",
    "    #left side offset padding\n",
    "    left_pad = np.uint8(np.ones((r, r_offset, d)) * 255)\n",
    "    img_lp = np.concatenate((left_pad, img),1)\n",
    "\n",
    "    #build right-side padding\n",
    "    rn, cn, d = np.shape(img_lp)\n",
    "    right_pad_amt = tile_size - cn%tile_size\n",
    "    right_pad = np.uint8(np.ones((rn, right_pad_amt,d)) * 255)\n",
    "    img_lrp = np.concatenate((img_lp,right_pad),1)\n",
    "\n",
    "    # top side offset padding\n",
    "    rn2, cn2, d = np.shape(img_lrp)\n",
    "    top_pad = np.uint8(np.ones((c_offset, cn2, d)) * 255)\n",
    "    img_lrtp = np.concatenate((top_pad, img_lrp),0)\n",
    "\n",
    "    #build bottom-side padding\n",
    "    rn3, cn3, d = np.shape(img_lrtp)\n",
    "    bot_pad_amt = tile_size - rn3%tile_size\n",
    "    bot_pad = np.uint8(np.ones((bot_pad_amt,cn3,d))*255)\n",
    "    img_lrtbp = np.concatenate((img_lrtp,bot_pad),0)\n",
    "    \n",
    "    \n",
    "    if (np.shape(img_lrtbp)[0] * np.shape(img_lrtbp)[1])/(tile_size*tile_size) < 12:\n",
    "        white_pad = np.uint8(np.ones((12 * tile_size,cn3,d))*255)\n",
    "        img_lrtbp = np.concatenate((img_lrtbp,white_pad),0)\n",
    "\n",
    "\n",
    "\n",
    "    im = img_lrtbp\n",
    "    M = tile_size\n",
    "    N = tile_size\n",
    "    tiles = [im[x:x+M,y:y+N] for x in range(0,im.shape[0],M) for y in range(0,im.shape[1],N)]\n",
    "    tiles = np.array(tiles)\n",
    "\n",
    "    num_tiles = len(tiles)\n",
    "\n",
    "    \n",
    "    counts = np.zeros(num_tiles)\n",
    "    for img_num in range(num_tiles):\n",
    "        counts[img_num] = (tiles[img_num]<255).sum()\n",
    "    tile_idx = np.argsort(counts)[-n:]\n",
    "    sub_tiles = tiles[tile_idx]\n",
    "    \n",
    " \n",
    "\n",
    "    #stick the subtiles together\n",
    "    x = 4\n",
    "    y = 3\n",
    "    tape = np.uint8(np.zeros((tile_size,0,3)))\n",
    "    for i in range(n):\n",
    "        tape = np.concatenate((tape,sub_tiles[i]),1)\n",
    "\n",
    "    num_rows = n/ipr\n",
    "    cols = np.shape(tape)\n",
    "    final_img = np.uint8(np.zeros((0,ipr*tile_size,3)))\n",
    "    idx = 0\n",
    "    for i in range(int(num_rows)):\n",
    "\n",
    "        final_img = np.concatenate((final_img, tape[0:tile_size,idx*tile_size*ipr:(idx+1)*tile_size*ipr,:]),0)\n",
    "        idx = idx + 1\n",
    "\n",
    "\n",
    "    return final_img"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TestingDataset(Dataset):\n",
    "    def __init__ (self, df, folder, transform = None):\n",
    "        self.df = df\n",
    "        self.folder = folder\n",
    "        self.transform = transform\n",
    "        \n",
    "    def __len__ (self):\n",
    "        return len(self.df)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        slide_identifier = self.df['image_id'].values[idx]\n",
    "        image_path = '/kaggle/input/prostate-cancer-grade-assessment/' + self.folder + '/'+ slide_identifier + '.tiff'\n",
    "        slide = io.MultiImage(image_path)\n",
    "        image = create_tiles(slide, tile_size = 128, r_offset = 0, c_offset = 0, n = 12, ipr = 4) #using the smallest image, denoted by [-1] index\n",
    "#         image = cv2.resize(image, (256, 256)) #downsampling to 256x256, slice and remove A index\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        \n",
    "        if self.transform:\n",
    "            transformed = self.transform(image = image)\n",
    "            image = transformed['image']\n",
    "        \n",
    "\n",
    "        return image"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Transformations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_transform(dataset_type):\n",
    "    assert dataset_type in ('train', 'valid')\n",
    "    if dataset_type == 'train':\n",
    "\n",
    "        return Compose([\n",
    "            HorizontalFlip(p=0.5),\n",
    "            VerticalFlip(p=0.5),\n",
    "            Normalize(\n",
    "                mean=[0.485, 0.456, 0.406],\n",
    "                std=[0.229, 0.224, 0.225],\n",
    "            ),\n",
    "            ToTensorV2(),\n",
    "        ])\n",
    "    elif dataset_type == 'valid':\n",
    "\n",
    "        return Compose([\n",
    "            Normalize(\n",
    "                mean=[0.485, 0.456, 0.406],\n",
    "                std=[0.229, 0.224, 0.225],\n",
    "            ),\n",
    "            ToTensorV2(),\n",
    "        ])"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function, division, absolute_import\n",
    "from collections import OrderedDict\n",
    "import math\n",
    "\n",
    "import torch.nn as nn\n",
    "from torch.utils import model_zoo\n",
    "\n",
    "class SEModule(nn.Module):\n",
    "\n",
    "    def __init__(self, channels, reduction):\n",
    "        super(SEModule, self).__init__()\n",
    "        self.avg_pool = nn.AdaptiveAvgPool2d(1)\n",
    "        self.fc1 = nn.Conv2d(channels, channels // reduction, kernel_size=1,\n",
    "                             padding=0)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.fc2 = nn.Conv2d(channels // reduction, channels, kernel_size=1,\n",
    "                             padding=0)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        module_input = x\n",
    "        x = self.avg_pool(x)\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.sigmoid(x)\n",
    "        return module_input * x\n",
    "\n",
    "\n",
    "class Bottleneck(nn.Module):\n",
    "    \"\"\"\n",
    "    Base class for bottlenecks that implements `forward()` method.\n",
    "    \"\"\"\n",
    "    def forward(self, x):\n",
    "        residual = x\n",
    "\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        out = self.conv3(out)\n",
    "        out = self.bn3(out)\n",
    "\n",
    "        if self.downsample is not None:\n",
    "            residual = self.downsample(x)\n",
    "\n",
    "        out = self.se_module(out) + residual\n",
    "        out = self.relu(out)\n",
    "\n",
    "        return out\n",
    "\n",
    "\n",
    "class SEBottleneck(Bottleneck):\n",
    "    \"\"\"\n",
    "    Bottleneck for SENet154.\n",
    "    \"\"\"\n",
    "    expansion = 4\n",
    "\n",
    "    def __init__(self, inplanes, planes, groups, reduction, stride=1,\n",
    "                 downsample=None):\n",
    "        super(SEBottleneck, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(inplanes, planes * 2, kernel_size=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(planes * 2)\n",
    "        self.conv2 = nn.Conv2d(planes * 2, planes * 4, kernel_size=3,\n",
    "                               stride=stride, padding=1, groups=groups,\n",
    "                               bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(planes * 4)\n",
    "        self.conv3 = nn.Conv2d(planes * 4, planes * 4, kernel_size=1,\n",
    "                               bias=False)\n",
    "        self.bn3 = nn.BatchNorm2d(planes * 4)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.se_module = SEModule(planes * 4, reduction=reduction)\n",
    "        self.downsample = downsample\n",
    "        self.stride = stride\n",
    "\n",
    "\n",
    "class SEResNetBottleneck(Bottleneck):\n",
    "    \"\"\"\n",
    "    ResNet bottleneck with a Squeeze-and-Excitation module. It follows Caffe\n",
    "    implementation and uses `stride=stride` in `conv1` and not in `conv2`\n",
    "    (the latter is used in the torchvision implementation of ResNet).\n",
    "    \"\"\"\n",
    "    expansion = 4\n",
    "\n",
    "    def __init__(self, inplanes, planes, groups, reduction, stride=1,\n",
    "                 downsample=None):\n",
    "        super(SEResNetBottleneck, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(inplanes, planes, kernel_size=1, bias=False,\n",
    "                               stride=stride)\n",
    "        self.bn1 = nn.BatchNorm2d(planes)\n",
    "        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, padding=1,\n",
    "                               groups=groups, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(planes)\n",
    "        self.conv3 = nn.Conv2d(planes, planes * 4, kernel_size=1, bias=False)\n",
    "        self.bn3 = nn.BatchNorm2d(planes * 4)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.se_module = SEModule(planes * 4, reduction=reduction)\n",
    "        self.downsample = downsample\n",
    "        self.stride = stride\n",
    "\n",
    "\n",
    "class SEResNeXtBottleneck(Bottleneck):\n",
    "    \"\"\"\n",
    "    ResNeXt bottleneck type C with a Squeeze-and-Excitation module.\n",
    "    \"\"\"\n",
    "    expansion = 4\n",
    "\n",
    "    def __init__(self, inplanes, planes, groups, reduction, stride=1,\n",
    "                 downsample=None, base_width=4):\n",
    "        super(SEResNeXtBottleneck, self).__init__()\n",
    "        width = math.floor(planes * (base_width / 64)) * groups\n",
    "        self.conv1 = nn.Conv2d(inplanes, width, kernel_size=1, bias=False,\n",
    "                               stride=1)\n",
    "        self.bn1 = nn.BatchNorm2d(width)\n",
    "        self.conv2 = nn.Conv2d(width, width, kernel_size=3, stride=stride,\n",
    "                               padding=1, groups=groups, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(width)\n",
    "        self.conv3 = nn.Conv2d(width, planes * 4, kernel_size=1, bias=False)\n",
    "        self.bn3 = nn.BatchNorm2d(planes * 4)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.se_module = SEModule(planes * 4, reduction=reduction)\n",
    "        self.downsample = downsample\n",
    "        self.stride = stride\n",
    "\n",
    "\n",
    "class SENet(nn.Module):\n",
    "\n",
    "    def __init__(self, block, layers, groups, reduction, dropout_p=0.2,\n",
    "                 inplanes=128, input_3x3=True, downsample_kernel_size=3,\n",
    "                 downsample_padding=1, num_classes=1000):\n",
    "        \"\"\"\n",
    "        Parameters\n",
    "        ----------\n",
    "        block (nn.Module): Bottleneck class.\n",
    "            - For SENet154: SEBottleneck\n",
    "            - For SE-ResNet models: SEResNetBottleneck\n",
    "            - For SE-ResNeXt models:  SEResNeXtBottleneck\n",
    "        layers (list of ints): Number of residual blocks for 4 layers of the\n",
    "            network (layer1...layer4).\n",
    "        groups (int): Number of groups for the 3x3 convolution in each\n",
    "            bottleneck block.\n",
    "            - For SENet154: 64\n",
    "            - For SE-ResNet models: 1\n",
    "            - For SE-ResNeXt models:  32\n",
    "        reduction (int): Reduction ratio for Squeeze-and-Excitation modules.\n",
    "            - For all models: 16\n",
    "        dropout_p (float or None): Drop probability for the Dropout layer.\n",
    "            If `None` the Dropout layer is not used.\n",
    "            - For SENet154: 0.2\n",
    "            - For SE-ResNet models: None\n",
    "            - For SE-ResNeXt models: None\n",
    "        inplanes (int):  Number of input channels for layer1.\n",
    "            - For SENet154: 128\n",
    "            - For SE-ResNet models: 64\n",
    "            - For SE-ResNeXt models: 64\n",
    "        input_3x3 (bool): If `True`, use three 3x3 convolutions instead of\n",
    "            a single 7x7 convolution in layer0.\n",
    "            - For SENet154: True\n",
    "            - For SE-ResNet models: False\n",
    "            - For SE-ResNeXt models: False\n",
    "        downsample_kernel_size (int): Kernel size for downsampling convolutions\n",
    "            in layer2, layer3 and layer4.\n",
    "            - For SENet154: 3\n",
    "            - For SE-ResNet models: 1\n",
    "            - For SE-ResNeXt models: 1\n",
    "        downsample_padding (int): Padding for downsampling convolutions in\n",
    "            layer2, layer3 and layer4.\n",
    "            - For SENet154: 1\n",
    "            - For SE-ResNet models: 0\n",
    "            - For SE-ResNeXt models: 0\n",
    "        num_classes (int): Number of outputs in `last_linear` layer.\n",
    "            - For all models: 1000\n",
    "        \"\"\"\n",
    "        super(SENet, self).__init__()\n",
    "        self.inplanes = inplanes\n",
    "        if input_3x3:\n",
    "            layer0_modules = [\n",
    "                ('conv1', nn.Conv2d(3, 64, 3, stride=2, padding=1,\n",
    "                                    bias=False)),\n",
    "                ('bn1', nn.BatchNorm2d(64)),\n",
    "                ('relu1', nn.ReLU(inplace=True)),\n",
    "                ('conv2', nn.Conv2d(64, 64, 3, stride=1, padding=1,\n",
    "                                    bias=False)),\n",
    "                ('bn2', nn.BatchNorm2d(64)),\n",
    "                ('relu2', nn.ReLU(inplace=True)),\n",
    "                ('conv3', nn.Conv2d(64, inplanes, 3, stride=1, padding=1,\n",
    "                                    bias=False)),\n",
    "                ('bn3', nn.BatchNorm2d(inplanes)),\n",
    "                ('relu3', nn.ReLU(inplace=True)),\n",
    "            ]\n",
    "        else:\n",
    "            layer0_modules = [\n",
    "                ('conv1', nn.Conv2d(3, inplanes, kernel_size=7, stride=2,\n",
    "                                    padding=3, bias=False)),\n",
    "                ('bn1', nn.BatchNorm2d(inplanes)),\n",
    "                ('relu1', nn.ReLU(inplace=True)),\n",
    "            ]\n",
    "        # To preserve compatibility with Caffe weights `ceil_mode=True`\n",
    "        # is used instead of `padding=1`.\n",
    "        layer0_modules.append(('pool', nn.MaxPool2d(3, stride=2,\n",
    "                                                    ceil_mode=True)))\n",
    "        self.layer0 = nn.Sequential(OrderedDict(layer0_modules))\n",
    "        self.layer1 = self._make_layer(\n",
    "            block,\n",
    "            planes=64,\n",
    "            blocks=layers[0],\n",
    "            groups=groups,\n",
    "            reduction=reduction,\n",
    "            downsample_kernel_size=1,\n",
    "            downsample_padding=0\n",
    "        )\n",
    "        self.layer2 = self._make_layer(\n",
    "            block,\n",
    "            planes=128,\n",
    "            blocks=layers[1],\n",
    "            stride=2,\n",
    "            groups=groups,\n",
    "            reduction=reduction,\n",
    "            downsample_kernel_size=downsample_kernel_size,\n",
    "            downsample_padding=downsample_padding\n",
    "        )\n",
    "        self.layer3 = self._make_layer(\n",
    "            block,\n",
    "            planes=256,\n",
    "            blocks=layers[2],\n",
    "            stride=2,\n",
    "            groups=groups,\n",
    "            reduction=reduction,\n",
    "            downsample_kernel_size=downsample_kernel_size,\n",
    "            downsample_padding=downsample_padding\n",
    "        )\n",
    "        self.layer4 = self._make_layer(\n",
    "            block,\n",
    "            planes=512,\n",
    "            blocks=layers[3],\n",
    "            stride=2,\n",
    "            groups=groups,\n",
    "            reduction=reduction,\n",
    "            downsample_kernel_size=downsample_kernel_size,\n",
    "            downsample_padding=downsample_padding\n",
    "        )\n",
    "        self.avg_pool = nn.AvgPool2d(7, stride=1)\n",
    "        self.dropout = nn.Dropout(dropout_p) if dropout_p is not None else None\n",
    "        self.last_linear = nn.Linear(512 * block.expansion, num_classes)\n",
    "\n",
    "    def _make_layer(self, block, planes, blocks, groups, reduction, stride=1,\n",
    "                    downsample_kernel_size=1, downsample_padding=0):\n",
    "        downsample = None\n",
    "        if stride != 1 or self.inplanes != planes * block.expansion:\n",
    "            downsample = nn.Sequential(\n",
    "                nn.Conv2d(self.inplanes, planes * block.expansion,\n",
    "                          kernel_size=downsample_kernel_size, stride=stride,\n",
    "                          padding=downsample_padding, bias=False),\n",
    "                nn.BatchNorm2d(planes * block.expansion),\n",
    "            )\n",
    "\n",
    "        layers = []\n",
    "        layers.append(block(self.inplanes, planes, groups, reduction, stride,\n",
    "                            downsample))\n",
    "        self.inplanes = planes * block.expansion\n",
    "        for i in range(1, blocks):\n",
    "            layers.append(block(self.inplanes, planes, groups, reduction))\n",
    "\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def features(self, x):\n",
    "        x = self.layer0(x)\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "        x = self.layer4(x)\n",
    "        return x\n",
    "\n",
    "    def logits(self, x):\n",
    "        x = self.avg_pool(x)\n",
    "        if self.dropout is not None:\n",
    "            x = self.dropout(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.last_linear(x)\n",
    "        return x\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = self.logits(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "def initialize_pretrained_model(model, num_classes, settings):\n",
    "    assert num_classes == settings['num_classes'], \\\n",
    "        'num_classes should be {}, but is {}'.format(\n",
    "            settings['num_classes'], num_classes)\n",
    "    model.load_state_dict(model_zoo.load_url(settings['url']))\n",
    "    model.input_space = settings['input_space']\n",
    "    model.input_size = settings['input_size']\n",
    "    model.input_range = settings['input_range']\n",
    "    model.mean = settings['mean']\n",
    "    model.std = settings['std']\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def se_resnext50_32x4d(num_classes=1000, pretrained='imagenet'):\n",
    "    model = SENet(SEResNeXtBottleneck, [3, 4, 6, 3], groups=32, reduction=16,\n",
    "                  dropout_p=None, inplanes=64, input_3x3=False,\n",
    "                  downsample_kernel_size=1, downsample_padding=0,\n",
    "                  num_classes=num_classes)\n",
    "    if pretrained is not None:\n",
    "        settings = pretrained_settings['se_resnext50_32x4d'][pretrained]\n",
    "        initialize_pretrained_model(model, num_classes, settings)\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class se_resnext(nn.Module):\n",
    "    def __init__(self, freeze = True):\n",
    "        super(se_resnext, self).__init__()\n",
    "#         layers = []\n",
    "#         layers.append(nn.Linear(512, 256))\n",
    "#         layers.append(nn.ReLU())\n",
    "#         layers.append(nn.Linear(256, 6))\n",
    "\n",
    "\n",
    "        self.model = se_resnext50_32x4d(pretrained = None)\n",
    "#         weights_path = '/kaggle/input/se-resnext50-32x4d/se_resnext50_32x4d-a260b3a4.pth'\n",
    "#         self.model.load_state_dict(torch.load(weights_path))\n",
    "        self.model.avg_pool = nn.AdaptiveAvgPool2d(1)\n",
    "        self.model.last_linear = nn.Linear(self.model.last_linear.in_features, 6)\n",
    "\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.model(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Inference and Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def submit(test_df, image_folder = 'test_images'):\n",
    "    if os.path.exists('/kaggle/input/prostate-cancer-grade-assessment/' + image_folder):\n",
    "        print('Running inference ---------->')\n",
    "        test_dataset = TestingDataset(test_df, image_folder, get_transform(dataset_type = 'valid'))\n",
    "        testloader = DataLoader(test_dataset, batch_size = 16, shuffle = False)\n",
    "        probs = []\n",
    "        for fold_num in range(2):\n",
    "            PATH = '/kaggle/input/resnext5032x4d/foldnum%s'% fold_num + 'se-resnext50-32x4d-2foldcv-e6.pth'\n",
    "            net = se_resnext(freeze = False)\n",
    "            net.load_state_dict(torch.load(PATH, map_location = device)) #might need to be changed\n",
    "            predicted = predict_test(net, testloader)\n",
    "            probs.append(predicted)\n",
    "        probs_avg = np.mean(probs,0)\n",
    "        predictions = probs_avg.argmax(1)\n",
    "        test_df['isup_grade'] = predictions\n",
    "#         test_df.insert(len(test_df.columns), 'isup_grade', predictions, allow_duplicates=True) #adds to last column\n",
    "    else:\n",
    "        print('directory not found')\n",
    "    return test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_test(net, dataloader):\n",
    "    predicted_mat = []\n",
    "    net.to(device)\n",
    "    for i, images in enumerate(tqdm(dataloader)):\n",
    "        images = images.to(device)\n",
    "        with torch.no_grad():\n",
    "            predicted = net(images)\n",
    "        predicted = predicted.to('cpu')\n",
    "        predicted = predicted.numpy()\n",
    "        predicted_mat.append(predicted)\n",
    "\n",
    "    predicted_mat = np.concatenate(predicted_mat)\n",
    "    return predicted_mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "directory not found\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_id</th>\n",
       "      <th>isup_grade</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>005700be7e06878e6605e7a5a39de1b2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>005c6e8877caf724c600fdce5d417d40</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0104f76634ff89bfff1ef0804a95c380</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           image_id  isup_grade\n",
       "0  005700be7e06878e6605e7a5a39de1b2           0\n",
       "1  005c6e8877caf724c600fdce5d417d40           0\n",
       "2  0104f76634ff89bfff1ef0804a95c380           0"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sampledf = pd.read_csv('/kaggle/input/prostate-cancer-grade-assessment/sample_submission.csv')\n",
    "submission = submit(sampledf, image_folder = 'test_images')\n",
    "submission['isup_grade'] = submission['isup_grade'].astype(int)\n",
    "submission.to_csv('submission.csv', index=False)\n",
    "submission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # On Training data sample:\n",
    "# sampledf = pd.read_csv('/kaggle/input/prostate-cancer-grade-assessment/sample_submission.csv')\n",
    "# submission = submit(train.head(), image_folder = 'train_images')\n",
    "# submission['isup_grade'] = submission['isup_grade'].astype(int)\n",
    "# submission.to_csv('submission.csv', index=False)\n",
    "# submission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
