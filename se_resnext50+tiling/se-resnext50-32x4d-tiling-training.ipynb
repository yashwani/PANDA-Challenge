{"cells":[{"metadata":{},"cell_type":"markdown","source":"Inspiration from: https://www.kaggle.com/yasufuminakama/panda-se-resnext50-classification-baseline"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\n\n# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":1,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Libraries"},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"#Imports\nfrom torch.utils.data import Dataset\nimport cv2\nimport openslide\nfrom skimage import io\nfrom sklearn.model_selection import StratifiedKFold\nfrom sklearn.metrics import cohen_kappa_score\n# from tqdm.notebook import tqdm\nfrom tqdm.notebook import trange, tqdm\nimport time\n\nimport torch\nimport torch.nn as nn\nimport torchvision.transforms as transforms\nimport torchvision\nimport torch.optim as optim\nfrom torch.utils.data import DataLoader, Dataset\n\nfrom albumentations import Compose, Normalize, HorizontalFlip, VerticalFlip\nfrom albumentations.pytorch import ToTensorV2\n\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\ndevice","execution_count":2,"outputs":[{"output_type":"execute_result","execution_count":2,"data":{"text/plain":"device(type='cuda')"},"metadata":{}}]},{"metadata":{},"cell_type":"markdown","source":"# Load into Pandas"},{"metadata":{"trusted":true},"cell_type":"code","source":"train = pd.read_csv('/kaggle/input/prostate-cancer-grade-assessment/train.csv')\ntrain.head()","execution_count":3,"outputs":[{"output_type":"execute_result","execution_count":3,"data":{"text/plain":"                           image_id data_provider  isup_grade gleason_score\n0  0005f7aaab2800f6170c399693a96917    karolinska           0           0+0\n1  000920ad0b612851f8e01bcc880d9b3d    karolinska           0           0+0\n2  0018ae58b01bdadc8e347995b69f99aa       radboud           4           4+4\n3  001c62abd11fa4b57bf7a6c603a11bb9    karolinska           4           4+4\n4  001d865e65ef5d2579c190a0e0350d8f    karolinska           0           0+0","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>image_id</th>\n      <th>data_provider</th>\n      <th>isup_grade</th>\n      <th>gleason_score</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0005f7aaab2800f6170c399693a96917</td>\n      <td>karolinska</td>\n      <td>0</td>\n      <td>0+0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>000920ad0b612851f8e01bcc880d9b3d</td>\n      <td>karolinska</td>\n      <td>0</td>\n      <td>0+0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0018ae58b01bdadc8e347995b69f99aa</td>\n      <td>radboud</td>\n      <td>4</td>\n      <td>4+4</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>001c62abd11fa4b57bf7a6c603a11bb9</td>\n      <td>karolinska</td>\n      <td>4</td>\n      <td>4+4</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>001d865e65ef5d2579c190a0e0350d8f</td>\n      <td>karolinska</td>\n      <td>0</td>\n      <td>0+0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"metadata":{},"cell_type":"markdown","source":"# Tiling"},{"metadata":{"trusted":true},"cell_type":"code","source":"def create_tiles(I, tile_size = 128, r_offset = 0, c_offset = 0, n = 12, ipr = 4):\n    \"\"\"\n    Params:\n        tile_size: n x n pixels per tile\n        r_offset: tiling starts n pixels left of input image left edge\n        c_offset: tiling: starts n pixels above input image top edge\n        n: total number of tiles in final stitched image\n        ipr: images per row in final stitched image\n    Returns:\n        final stitched image\n    \"\"\"\n\n    img = I[-1]\n    r, c, d = np.shape(img)\n\n\n    #left side offset padding\n    left_pad = np.uint8(np.ones((r, r_offset, d)) * 255)\n    img_lp = np.concatenate((left_pad, img),1)\n\n    #build right-side padding\n    rn, cn, d = np.shape(img_lp)\n    right_pad_amt = tile_size - cn%tile_size\n    right_pad = np.uint8(np.ones((rn, right_pad_amt,d)) * 255)\n    img_lrp = np.concatenate((img_lp,right_pad),1)\n\n    # top side offset padding\n    rn2, cn2, d = np.shape(img_lrp)\n    top_pad = np.uint8(np.ones((c_offset, cn2, d)) * 255)\n    img_lrtp = np.concatenate((top_pad, img_lrp),0)\n\n    #build bottom-side padding\n    rn3, cn3, d = np.shape(img_lrtp)\n    bot_pad_amt = tile_size - rn3%tile_size\n    bot_pad = np.uint8(np.ones((bot_pad_amt,cn3,d))*255)\n    img_lrtbp = np.concatenate((img_lrtp,bot_pad),0)\n    \n    \n    if (np.shape(img_lrtbp)[0] * np.shape(img_lrtbp)[1])/(tile_size*tile_size) < 12:\n        white_pad = np.uint8(np.ones((12 * tile_size,cn3,d))*255)\n        img_lrtbp = np.concatenate((img_lrtbp,white_pad),0)\n\n\n\n    im = img_lrtbp\n    M = tile_size\n    N = tile_size\n    tiles = [im[x:x+M,y:y+N] for x in range(0,im.shape[0],M) for y in range(0,im.shape[1],N)]\n    tiles = np.array(tiles)\n\n    num_tiles = len(tiles)\n\n    \n    counts = np.zeros(num_tiles)\n    for img_num in range(num_tiles):\n        counts[img_num] = (tiles[img_num]<255).sum()\n    tile_idx = np.argsort(counts)[-n:]\n    sub_tiles = tiles[tile_idx]\n    \n \n\n    #stick the subtiles together\n    x = 4\n    y = 3\n    tape = np.uint8(np.zeros((tile_size,0,3)))\n    for i in range(n):\n        tape = np.concatenate((tape,sub_tiles[i]),1)\n\n    num_rows = n/ipr\n    cols = np.shape(tape)\n    final_img = np.uint8(np.zeros((0,ipr*tile_size,3)))\n    idx = 0\n    for i in range(int(num_rows)):\n\n        final_img = np.concatenate((final_img, tape[0:tile_size,idx*tile_size*ipr:(idx+1)*tile_size*ipr,:]),0)\n        idx = idx + 1\n\n\n    return final_img","execution_count":4,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Dataset"},{"metadata":{"trusted":true},"cell_type":"code","source":"class TrainingDataset(Dataset):\n    def __init__ (self, df, labels, transform = None):\n        self.df = df\n        self.labels = labels\n        self.transform = transform\n        \n    def __len__ (self):\n        return len(self.df)\n    \n    def __getitem__(self, idx):\n        slide_identifier = self.df['image_id'].values[idx]\n        image_path = '/kaggle/input/prostate-cancer-grade-assessment/train_images/' + slide_identifier + '.tiff'\n        slide = io.MultiImage(image_path)\n        image = create_tiles(slide, tile_size = 128, r_offset = 0, c_offset = 0, n = 12, ipr = 4) #using the smallest image, denoted by [-1] index\n#         image = cv2.resize(image, (256, 256)) #downsampling to 256x256, slice and remove A index\n        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n        \n        if self.transform:\n            transformed = self.transform(image = image)\n            image = transformed['image']\n        \n        label = self.labels[idx]\n        return image, label\n    \nclass TestingDataset(Dataset):\n    def __init__ (self, df, folder, transform = None):\n        self.df = df\n        self.folder = folder\n        self.transform = transform\n        \n    def __len__ (self):\n        return len(self.df)\n    \n    def __getitem__(self, idx):\n        slide_identifier = self.df['image_id'].values[idx]\n        image_path = '/kaggle/input/prostate-cancer-grade-assessment/' + self.folder + '/'+ slide_identifier + '.tiff'\n        slide = io.MultiImage(image_path)\n        image = create_tiles(slide, tile_size = 128, r_offset = 0, c_offset = 0, n = 12, ipr = 4) #using the smallest image, denoted by [-1] index\n#         image = cv2.resize(image, (256, 256)) #downsampling to 256x256, slice and remove A index\n        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n        \n        if self.transform:\n            transformed = self.transform(image = image)\n            image = transformed['image']\n        \n\n        return image","execution_count":5,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Transformations"},{"metadata":{"trusted":true},"cell_type":"code","source":"def get_transform(dataset_type):\n    assert dataset_type in ('train', 'valid')\n    if dataset_type == 'train':\n\n        return Compose([\n            HorizontalFlip(p=0.5),\n            VerticalFlip(p=0.5),\n            Normalize(\n                mean=[0.485, 0.456, 0.406],\n                std=[0.229, 0.224, 0.225],\n            ),\n            ToTensorV2(),\n        ])\n    elif dataset_type == 'valid':\n\n        return Compose([\n            Normalize(\n                mean=[0.485, 0.456, 0.406],\n                std=[0.229, 0.224, 0.225],\n            ),\n            ToTensorV2(),\n        ])","execution_count":6,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Split Dataset Into n (4) Folds"},{"metadata":{"trusted":true},"cell_type":"code","source":"fold_dataset = train.copy()\nkfold = StratifiedKFold(n_splits = 4, shuffle = True ,random_state = 42)\ngen = kfold.split(fold_dataset, fold_dataset['isup_grade']) #create generator\nfor fold, (train_,test_) in enumerate(gen): \n    fold_dataset.loc[test_, 'fold'] = fold #assign fold number to indices for test (1/4 of dataset)\nfold_dataset['fold'] = fold_dataset['fold'].astype(int) #change to integer\nfold_dataset.head()","execution_count":7,"outputs":[{"output_type":"execute_result","execution_count":7,"data":{"text/plain":"                           image_id data_provider  isup_grade gleason_score  \\\n0  0005f7aaab2800f6170c399693a96917    karolinska           0           0+0   \n1  000920ad0b612851f8e01bcc880d9b3d    karolinska           0           0+0   \n2  0018ae58b01bdadc8e347995b69f99aa       radboud           4           4+4   \n3  001c62abd11fa4b57bf7a6c603a11bb9    karolinska           4           4+4   \n4  001d865e65ef5d2579c190a0e0350d8f    karolinska           0           0+0   \n\n   fold  \n0     3  \n1     0  \n2     2  \n3     3  \n4     3  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>image_id</th>\n      <th>data_provider</th>\n      <th>isup_grade</th>\n      <th>gleason_score</th>\n      <th>fold</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0005f7aaab2800f6170c399693a96917</td>\n      <td>karolinska</td>\n      <td>0</td>\n      <td>0+0</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>000920ad0b612851f8e01bcc880d9b3d</td>\n      <td>karolinska</td>\n      <td>0</td>\n      <td>0+0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0018ae58b01bdadc8e347995b69f99aa</td>\n      <td>radboud</td>\n      <td>4</td>\n      <td>4+4</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>001c62abd11fa4b57bf7a6c603a11bb9</td>\n      <td>karolinska</td>\n      <td>4</td>\n      <td>4+4</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>001d865e65ef5d2579c190a0e0350d8f</td>\n      <td>karolinska</td>\n      <td>0</td>\n      <td>0+0</td>\n      <td>3</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"metadata":{},"cell_type":"markdown","source":"# Build Model"},{"metadata":{},"cell_type":"markdown","source":"resnext50_32x4d: https://github.com/pytorch/vision/blob/master/torchvision/models/resnet.py\n\nweights: https://download.pytorch.org/models/resnext50_32x4d-7cdf4587.pth"},{"metadata":{"trusted":true},"cell_type":"code","source":"from __future__ import print_function, division, absolute_import\nfrom collections import OrderedDict\nimport math\n\nimport torch.nn as nn\nfrom torch.utils import model_zoo\n\nclass SEModule(nn.Module):\n\n    def __init__(self, channels, reduction):\n        super(SEModule, self).__init__()\n        self.avg_pool = nn.AdaptiveAvgPool2d(1)\n        self.fc1 = nn.Conv2d(channels, channels // reduction, kernel_size=1,\n                             padding=0)\n        self.relu = nn.ReLU(inplace=True)\n        self.fc2 = nn.Conv2d(channels // reduction, channels, kernel_size=1,\n                             padding=0)\n        self.sigmoid = nn.Sigmoid()\n\n    def forward(self, x):\n        module_input = x\n        x = self.avg_pool(x)\n        x = self.fc1(x)\n        x = self.relu(x)\n        x = self.fc2(x)\n        x = self.sigmoid(x)\n        return module_input * x\n\n\nclass Bottleneck(nn.Module):\n    \"\"\"\n    Base class for bottlenecks that implements `forward()` method.\n    \"\"\"\n    def forward(self, x):\n        residual = x\n\n        out = self.conv1(x)\n        out = self.bn1(out)\n        out = self.relu(out)\n\n        out = self.conv2(out)\n        out = self.bn2(out)\n        out = self.relu(out)\n\n        out = self.conv3(out)\n        out = self.bn3(out)\n\n        if self.downsample is not None:\n            residual = self.downsample(x)\n\n        out = self.se_module(out) + residual\n        out = self.relu(out)\n\n        return out\n\n\nclass SEBottleneck(Bottleneck):\n    \"\"\"\n    Bottleneck for SENet154.\n    \"\"\"\n    expansion = 4\n\n    def __init__(self, inplanes, planes, groups, reduction, stride=1,\n                 downsample=None):\n        super(SEBottleneck, self).__init__()\n        self.conv1 = nn.Conv2d(inplanes, planes * 2, kernel_size=1, bias=False)\n        self.bn1 = nn.BatchNorm2d(planes * 2)\n        self.conv2 = nn.Conv2d(planes * 2, planes * 4, kernel_size=3,\n                               stride=stride, padding=1, groups=groups,\n                               bias=False)\n        self.bn2 = nn.BatchNorm2d(planes * 4)\n        self.conv3 = nn.Conv2d(planes * 4, planes * 4, kernel_size=1,\n                               bias=False)\n        self.bn3 = nn.BatchNorm2d(planes * 4)\n        self.relu = nn.ReLU(inplace=True)\n        self.se_module = SEModule(planes * 4, reduction=reduction)\n        self.downsample = downsample\n        self.stride = stride\n\n\nclass SEResNetBottleneck(Bottleneck):\n    \"\"\"\n    ResNet bottleneck with a Squeeze-and-Excitation module. It follows Caffe\n    implementation and uses `stride=stride` in `conv1` and not in `conv2`\n    (the latter is used in the torchvision implementation of ResNet).\n    \"\"\"\n    expansion = 4\n\n    def __init__(self, inplanes, planes, groups, reduction, stride=1,\n                 downsample=None):\n        super(SEResNetBottleneck, self).__init__()\n        self.conv1 = nn.Conv2d(inplanes, planes, kernel_size=1, bias=False,\n                               stride=stride)\n        self.bn1 = nn.BatchNorm2d(planes)\n        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, padding=1,\n                               groups=groups, bias=False)\n        self.bn2 = nn.BatchNorm2d(planes)\n        self.conv3 = nn.Conv2d(planes, planes * 4, kernel_size=1, bias=False)\n        self.bn3 = nn.BatchNorm2d(planes * 4)\n        self.relu = nn.ReLU(inplace=True)\n        self.se_module = SEModule(planes * 4, reduction=reduction)\n        self.downsample = downsample\n        self.stride = stride\n\n\nclass SEResNeXtBottleneck(Bottleneck):\n    \"\"\"\n    ResNeXt bottleneck type C with a Squeeze-and-Excitation module.\n    \"\"\"\n    expansion = 4\n\n    def __init__(self, inplanes, planes, groups, reduction, stride=1,\n                 downsample=None, base_width=4):\n        super(SEResNeXtBottleneck, self).__init__()\n        width = math.floor(planes * (base_width / 64)) * groups\n        self.conv1 = nn.Conv2d(inplanes, width, kernel_size=1, bias=False,\n                               stride=1)\n        self.bn1 = nn.BatchNorm2d(width)\n        self.conv2 = nn.Conv2d(width, width, kernel_size=3, stride=stride,\n                               padding=1, groups=groups, bias=False)\n        self.bn2 = nn.BatchNorm2d(width)\n        self.conv3 = nn.Conv2d(width, planes * 4, kernel_size=1, bias=False)\n        self.bn3 = nn.BatchNorm2d(planes * 4)\n        self.relu = nn.ReLU(inplace=True)\n        self.se_module = SEModule(planes * 4, reduction=reduction)\n        self.downsample = downsample\n        self.stride = stride\n\n\nclass SENet(nn.Module):\n\n    def __init__(self, block, layers, groups, reduction, dropout_p=0.2,\n                 inplanes=128, input_3x3=True, downsample_kernel_size=3,\n                 downsample_padding=1, num_classes=1000):\n        \"\"\"\n        Parameters\n        ----------\n        block (nn.Module): Bottleneck class.\n            - For SENet154: SEBottleneck\n            - For SE-ResNet models: SEResNetBottleneck\n            - For SE-ResNeXt models:  SEResNeXtBottleneck\n        layers (list of ints): Number of residual blocks for 4 layers of the\n            network (layer1...layer4).\n        groups (int): Number of groups for the 3x3 convolution in each\n            bottleneck block.\n            - For SENet154: 64\n            - For SE-ResNet models: 1\n            - For SE-ResNeXt models:  32\n        reduction (int): Reduction ratio for Squeeze-and-Excitation modules.\n            - For all models: 16\n        dropout_p (float or None): Drop probability for the Dropout layer.\n            If `None` the Dropout layer is not used.\n            - For SENet154: 0.2\n            - For SE-ResNet models: None\n            - For SE-ResNeXt models: None\n        inplanes (int):  Number of input channels for layer1.\n            - For SENet154: 128\n            - For SE-ResNet models: 64\n            - For SE-ResNeXt models: 64\n        input_3x3 (bool): If `True`, use three 3x3 convolutions instead of\n            a single 7x7 convolution in layer0.\n            - For SENet154: True\n            - For SE-ResNet models: False\n            - For SE-ResNeXt models: False\n        downsample_kernel_size (int): Kernel size for downsampling convolutions\n            in layer2, layer3 and layer4.\n            - For SENet154: 3\n            - For SE-ResNet models: 1\n            - For SE-ResNeXt models: 1\n        downsample_padding (int): Padding for downsampling convolutions in\n            layer2, layer3 and layer4.\n            - For SENet154: 1\n            - For SE-ResNet models: 0\n            - For SE-ResNeXt models: 0\n        num_classes (int): Number of outputs in `last_linear` layer.\n            - For all models: 1000\n        \"\"\"\n        super(SENet, self).__init__()\n        self.inplanes = inplanes\n        if input_3x3:\n            layer0_modules = [\n                ('conv1', nn.Conv2d(3, 64, 3, stride=2, padding=1,\n                                    bias=False)),\n                ('bn1', nn.BatchNorm2d(64)),\n                ('relu1', nn.ReLU(inplace=True)),\n                ('conv2', nn.Conv2d(64, 64, 3, stride=1, padding=1,\n                                    bias=False)),\n                ('bn2', nn.BatchNorm2d(64)),\n                ('relu2', nn.ReLU(inplace=True)),\n                ('conv3', nn.Conv2d(64, inplanes, 3, stride=1, padding=1,\n                                    bias=False)),\n                ('bn3', nn.BatchNorm2d(inplanes)),\n                ('relu3', nn.ReLU(inplace=True)),\n            ]\n        else:\n            layer0_modules = [\n                ('conv1', nn.Conv2d(3, inplanes, kernel_size=7, stride=2,\n                                    padding=3, bias=False)),\n                ('bn1', nn.BatchNorm2d(inplanes)),\n                ('relu1', nn.ReLU(inplace=True)),\n            ]\n        # To preserve compatibility with Caffe weights `ceil_mode=True`\n        # is used instead of `padding=1`.\n        layer0_modules.append(('pool', nn.MaxPool2d(3, stride=2,\n                                                    ceil_mode=True)))\n        self.layer0 = nn.Sequential(OrderedDict(layer0_modules))\n        self.layer1 = self._make_layer(\n            block,\n            planes=64,\n            blocks=layers[0],\n            groups=groups,\n            reduction=reduction,\n            downsample_kernel_size=1,\n            downsample_padding=0\n        )\n        self.layer2 = self._make_layer(\n            block,\n            planes=128,\n            blocks=layers[1],\n            stride=2,\n            groups=groups,\n            reduction=reduction,\n            downsample_kernel_size=downsample_kernel_size,\n            downsample_padding=downsample_padding\n        )\n        self.layer3 = self._make_layer(\n            block,\n            planes=256,\n            blocks=layers[2],\n            stride=2,\n            groups=groups,\n            reduction=reduction,\n            downsample_kernel_size=downsample_kernel_size,\n            downsample_padding=downsample_padding\n        )\n        self.layer4 = self._make_layer(\n            block,\n            planes=512,\n            blocks=layers[3],\n            stride=2,\n            groups=groups,\n            reduction=reduction,\n            downsample_kernel_size=downsample_kernel_size,\n            downsample_padding=downsample_padding\n        )\n        self.avg_pool = nn.AvgPool2d(7, stride=1)\n        self.dropout = nn.Dropout(dropout_p) if dropout_p is not None else None\n        self.last_linear = nn.Linear(512 * block.expansion, num_classes)\n\n    def _make_layer(self, block, planes, blocks, groups, reduction, stride=1,\n                    downsample_kernel_size=1, downsample_padding=0):\n        downsample = None\n        if stride != 1 or self.inplanes != planes * block.expansion:\n            downsample = nn.Sequential(\n                nn.Conv2d(self.inplanes, planes * block.expansion,\n                          kernel_size=downsample_kernel_size, stride=stride,\n                          padding=downsample_padding, bias=False),\n                nn.BatchNorm2d(planes * block.expansion),\n            )\n\n        layers = []\n        layers.append(block(self.inplanes, planes, groups, reduction, stride,\n                            downsample))\n        self.inplanes = planes * block.expansion\n        for i in range(1, blocks):\n            layers.append(block(self.inplanes, planes, groups, reduction))\n\n        return nn.Sequential(*layers)\n\n    def features(self, x):\n        x = self.layer0(x)\n        x = self.layer1(x)\n        x = self.layer2(x)\n        x = self.layer3(x)\n        x = self.layer4(x)\n        return x\n\n    def logits(self, x):\n        x = self.avg_pool(x)\n        if self.dropout is not None:\n            x = self.dropout(x)\n        x = x.view(x.size(0), -1)\n        x = self.last_linear(x)\n        return x\n\n    def forward(self, x):\n        x = self.features(x)\n        x = self.logits(x)\n        return x\n\n\ndef initialize_pretrained_model(model, num_classes, settings):\n    assert num_classes == settings['num_classes'], \\\n        'num_classes should be {}, but is {}'.format(\n            settings['num_classes'], num_classes)\n    model.load_state_dict(model_zoo.load_url(settings['url']))\n    model.input_space = settings['input_space']\n    model.input_size = settings['input_size']\n    model.input_range = settings['input_range']\n    model.mean = settings['mean']\n    model.std = settings['std']\n\n\n\n\ndef se_resnext50_32x4d(num_classes=1000, pretrained='imagenet'):\n    model = SENet(SEResNeXtBottleneck, [3, 4, 6, 3], groups=32, reduction=16,\n                  dropout_p=None, inplanes=64, input_3x3=False,\n                  downsample_kernel_size=1, downsample_padding=0,\n                  num_classes=num_classes)\n    if pretrained is not None:\n        settings = pretrained_settings['se_resnext50_32x4d'][pretrained]\n        initialize_pretrained_model(model, num_classes, settings)\n    return model\n\n","execution_count":8,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class se_resnext(nn.Module):\n    def __init__(self, freeze = True):\n        super(se_resnext, self).__init__()\n#         layers = []\n#         layers.append(nn.Linear(512, 256))\n#         layers.append(nn.ReLU())\n#         layers.append(nn.Linear(256, 6))\n\n\n        self.model = se_resnext50_32x4d(pretrained = None)\n        weights_path = '/kaggle/input/se-resnext50-32x4d/se_resnext50_32x4d-a260b3a4.pth'\n        self.model.load_state_dict(torch.load(weights_path))\n        self.model.avg_pool = nn.AdaptiveAvgPool2d(1)\n        self.model.last_linear = nn.Linear(self.model.last_linear.in_features, 6)\n\n        \n    def forward(self, x):\n        x = self.model(x)\n        return x","execution_count":9,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"net = se_resnext()\nnet","execution_count":10,"outputs":[{"output_type":"execute_result","execution_count":10,"data":{"text/plain":"se_resnext(\n  (model): SENet(\n    (layer0): Sequential(\n      (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu1): ReLU(inplace=True)\n      (pool): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=True)\n    )\n    (layer1): Sequential(\n      (0): SEResNeXtBottleneck(\n        (conv1): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv3): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu): ReLU(inplace=True)\n        (se_module): SEModule(\n          (avg_pool): AdaptiveAvgPool2d(output_size=1)\n          (fc1): Conv2d(256, 16, kernel_size=(1, 1), stride=(1, 1))\n          (relu): ReLU(inplace=True)\n          (fc2): Conv2d(16, 256, kernel_size=(1, 1), stride=(1, 1))\n          (sigmoid): Sigmoid()\n        )\n        (downsample): Sequential(\n          (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        )\n      )\n      (1): SEResNeXtBottleneck(\n        (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv3): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu): ReLU(inplace=True)\n        (se_module): SEModule(\n          (avg_pool): AdaptiveAvgPool2d(output_size=1)\n          (fc1): Conv2d(256, 16, kernel_size=(1, 1), stride=(1, 1))\n          (relu): ReLU(inplace=True)\n          (fc2): Conv2d(16, 256, kernel_size=(1, 1), stride=(1, 1))\n          (sigmoid): Sigmoid()\n        )\n      )\n      (2): SEResNeXtBottleneck(\n        (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv3): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu): ReLU(inplace=True)\n        (se_module): SEModule(\n          (avg_pool): AdaptiveAvgPool2d(output_size=1)\n          (fc1): Conv2d(256, 16, kernel_size=(1, 1), stride=(1, 1))\n          (relu): ReLU(inplace=True)\n          (fc2): Conv2d(16, 256, kernel_size=(1, 1), stride=(1, 1))\n          (sigmoid): Sigmoid()\n        )\n      )\n    )\n    (layer2): Sequential(\n      (0): SEResNeXtBottleneck(\n        (conv1): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=32, bias=False)\n        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv3): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu): ReLU(inplace=True)\n        (se_module): SEModule(\n          (avg_pool): AdaptiveAvgPool2d(output_size=1)\n          (fc1): Conv2d(512, 32, kernel_size=(1, 1), stride=(1, 1))\n          (relu): ReLU(inplace=True)\n          (fc2): Conv2d(32, 512, kernel_size=(1, 1), stride=(1, 1))\n          (sigmoid): Sigmoid()\n        )\n        (downsample): Sequential(\n          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        )\n      )\n      (1): SEResNeXtBottleneck(\n        (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv3): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu): ReLU(inplace=True)\n        (se_module): SEModule(\n          (avg_pool): AdaptiveAvgPool2d(output_size=1)\n          (fc1): Conv2d(512, 32, kernel_size=(1, 1), stride=(1, 1))\n          (relu): ReLU(inplace=True)\n          (fc2): Conv2d(32, 512, kernel_size=(1, 1), stride=(1, 1))\n          (sigmoid): Sigmoid()\n        )\n      )\n      (2): SEResNeXtBottleneck(\n        (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv3): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu): ReLU(inplace=True)\n        (se_module): SEModule(\n          (avg_pool): AdaptiveAvgPool2d(output_size=1)\n          (fc1): Conv2d(512, 32, kernel_size=(1, 1), stride=(1, 1))\n          (relu): ReLU(inplace=True)\n          (fc2): Conv2d(32, 512, kernel_size=(1, 1), stride=(1, 1))\n          (sigmoid): Sigmoid()\n        )\n      )\n      (3): SEResNeXtBottleneck(\n        (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv3): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu): ReLU(inplace=True)\n        (se_module): SEModule(\n          (avg_pool): AdaptiveAvgPool2d(output_size=1)\n          (fc1): Conv2d(512, 32, kernel_size=(1, 1), stride=(1, 1))\n          (relu): ReLU(inplace=True)\n          (fc2): Conv2d(32, 512, kernel_size=(1, 1), stride=(1, 1))\n          (sigmoid): Sigmoid()\n        )\n      )\n    )\n    (layer3): Sequential(\n      (0): SEResNeXtBottleneck(\n        (conv1): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=32, bias=False)\n        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv3): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu): ReLU(inplace=True)\n        (se_module): SEModule(\n          (avg_pool): AdaptiveAvgPool2d(output_size=1)\n          (fc1): Conv2d(1024, 64, kernel_size=(1, 1), stride=(1, 1))\n          (relu): ReLU(inplace=True)\n          (fc2): Conv2d(64, 1024, kernel_size=(1, 1), stride=(1, 1))\n          (sigmoid): Sigmoid()\n        )\n        (downsample): Sequential(\n          (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n          (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        )\n      )\n      (1): SEResNeXtBottleneck(\n        (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv3): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu): ReLU(inplace=True)\n        (se_module): SEModule(\n          (avg_pool): AdaptiveAvgPool2d(output_size=1)\n          (fc1): Conv2d(1024, 64, kernel_size=(1, 1), stride=(1, 1))\n          (relu): ReLU(inplace=True)\n          (fc2): Conv2d(64, 1024, kernel_size=(1, 1), stride=(1, 1))\n          (sigmoid): Sigmoid()\n        )\n      )\n      (2): SEResNeXtBottleneck(\n        (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv3): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu): ReLU(inplace=True)\n        (se_module): SEModule(\n          (avg_pool): AdaptiveAvgPool2d(output_size=1)\n          (fc1): Conv2d(1024, 64, kernel_size=(1, 1), stride=(1, 1))\n          (relu): ReLU(inplace=True)\n          (fc2): Conv2d(64, 1024, kernel_size=(1, 1), stride=(1, 1))\n          (sigmoid): Sigmoid()\n        )\n      )\n      (3): SEResNeXtBottleneck(\n        (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv3): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu): ReLU(inplace=True)\n        (se_module): SEModule(\n          (avg_pool): AdaptiveAvgPool2d(output_size=1)\n          (fc1): Conv2d(1024, 64, kernel_size=(1, 1), stride=(1, 1))\n          (relu): ReLU(inplace=True)\n          (fc2): Conv2d(64, 1024, kernel_size=(1, 1), stride=(1, 1))\n          (sigmoid): Sigmoid()\n        )\n      )\n      (4): SEResNeXtBottleneck(\n        (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv3): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu): ReLU(inplace=True)\n        (se_module): SEModule(\n          (avg_pool): AdaptiveAvgPool2d(output_size=1)\n          (fc1): Conv2d(1024, 64, kernel_size=(1, 1), stride=(1, 1))\n          (relu): ReLU(inplace=True)\n          (fc2): Conv2d(64, 1024, kernel_size=(1, 1), stride=(1, 1))\n          (sigmoid): Sigmoid()\n        )\n      )\n      (5): SEResNeXtBottleneck(\n        (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv3): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu): ReLU(inplace=True)\n        (se_module): SEModule(\n          (avg_pool): AdaptiveAvgPool2d(output_size=1)\n          (fc1): Conv2d(1024, 64, kernel_size=(1, 1), stride=(1, 1))\n          (relu): ReLU(inplace=True)\n          (fc2): Conv2d(64, 1024, kernel_size=(1, 1), stride=(1, 1))\n          (sigmoid): Sigmoid()\n        )\n      )\n    )\n    (layer4): Sequential(\n      (0): SEResNeXtBottleneck(\n        (conv1): Conv2d(1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv2): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=32, bias=False)\n        (bn2): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv3): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu): ReLU(inplace=True)\n        (se_module): SEModule(\n          (avg_pool): AdaptiveAvgPool2d(output_size=1)\n          (fc1): Conv2d(2048, 128, kernel_size=(1, 1), stride=(1, 1))\n          (relu): ReLU(inplace=True)\n          (fc2): Conv2d(128, 2048, kernel_size=(1, 1), stride=(1, 1))\n          (sigmoid): Sigmoid()\n        )\n        (downsample): Sequential(\n          (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n          (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        )\n      )\n      (1): SEResNeXtBottleneck(\n        (conv1): Conv2d(2048, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv2): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n        (bn2): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv3): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu): ReLU(inplace=True)\n        (se_module): SEModule(\n          (avg_pool): AdaptiveAvgPool2d(output_size=1)\n          (fc1): Conv2d(2048, 128, kernel_size=(1, 1), stride=(1, 1))\n          (relu): ReLU(inplace=True)\n          (fc2): Conv2d(128, 2048, kernel_size=(1, 1), stride=(1, 1))\n          (sigmoid): Sigmoid()\n        )\n      )\n      (2): SEResNeXtBottleneck(\n        (conv1): Conv2d(2048, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv2): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n        (bn2): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv3): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu): ReLU(inplace=True)\n        (se_module): SEModule(\n          (avg_pool): AdaptiveAvgPool2d(output_size=1)\n          (fc1): Conv2d(2048, 128, kernel_size=(1, 1), stride=(1, 1))\n          (relu): ReLU(inplace=True)\n          (fc2): Conv2d(128, 2048, kernel_size=(1, 1), stride=(1, 1))\n          (sigmoid): Sigmoid()\n        )\n      )\n    )\n    (avg_pool): AdaptiveAvgPool2d(output_size=1)\n    (last_linear): Linear(in_features=2048, out_features=6, bias=True)\n  )\n)"},"metadata":{}}]},{"metadata":{},"cell_type":"markdown","source":"# Train on 90%, validate on 10%"},{"metadata":{"trusted":true},"cell_type":"code","source":"fold_dataset = train.copy()\nkfold = StratifiedKFold(n_splits = 2, shuffle = True ,random_state = 42)\ngen = kfold.split(fold_dataset, fold_dataset['isup_grade']) #create generator\nfor fold, (train_,test_) in enumerate(gen): \n    fold_dataset.loc[test_, 'fold'] = fold #assign fold number to indices for test (1/4 of dataset)\nfold_dataset['fold'] = fold_dataset['fold'].astype(int) #change to integer\nfold_dataset.head()","execution_count":12,"outputs":[{"output_type":"execute_result","execution_count":12,"data":{"text/plain":"                           image_id data_provider  isup_grade gleason_score  \\\n0  0005f7aaab2800f6170c399693a96917    karolinska           0           0+0   \n1  000920ad0b612851f8e01bcc880d9b3d    karolinska           0           0+0   \n2  0018ae58b01bdadc8e347995b69f99aa       radboud           4           4+4   \n3  001c62abd11fa4b57bf7a6c603a11bb9    karolinska           4           4+4   \n4  001d865e65ef5d2579c190a0e0350d8f    karolinska           0           0+0   \n\n   fold  \n0     1  \n1     0  \n2     1  \n3     1  \n4     1  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>image_id</th>\n      <th>data_provider</th>\n      <th>isup_grade</th>\n      <th>gleason_score</th>\n      <th>fold</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0005f7aaab2800f6170c399693a96917</td>\n      <td>karolinska</td>\n      <td>0</td>\n      <td>0+0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>000920ad0b612851f8e01bcc880d9b3d</td>\n      <td>karolinska</td>\n      <td>0</td>\n      <td>0+0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0018ae58b01bdadc8e347995b69f99aa</td>\n      <td>radboud</td>\n      <td>4</td>\n      <td>4+4</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>001c62abd11fa4b57bf7a6c603a11bb9</td>\n      <td>karolinska</td>\n      <td>4</td>\n      <td>4+4</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>001d865e65ef5d2579c190a0e0350d8f</td>\n      <td>karolinska</td>\n      <td>0</td>\n      <td>0+0</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":" def training_(fold_num, num_epochs):\n        \n        # get the dataset from fold_dataset for current fold #################################################################\n        print('Fold number %s:' % fold_num)\n        \n        train_df = fold_dataset.loc[fold_dataset['fold'] != fold_num].reset_index(drop = True)\n        valid_df = fold_dataset.loc[fold_dataset['fold'] == fold_num].reset_index(drop = True)\n        \n        train_label = train_df['isup_grade']\n        valid_label = valid_df['isup_grade']\n        \n        train_dataset = TrainingDataset(train_df, train_label, get_transform(dataset_type = 'train'))\n        valid_dataset = TrainingDataset(valid_df, valid_label, get_transform(dataset_type = 'valid'))\n        \n        trainloader = DataLoader(train_dataset, batch_size = 16)\n        validloader = DataLoader(valid_dataset, batch_size = 16)\n        \n        # initialize model, and set criterion, optimizer, scheduler #################################################################\n#         net = VGG('VGG16', dropout_rate = 0)\n        net = se_resnext(freeze = False)\n        net.to(device)\n        criterion = nn.CrossEntropyLoss()\n        criterion.to(device)\n#         optimizer = optim.SGD(net.parameters(), lr = 0.1, momentum = 0.9, weight_decay=5e-4)\n        optimizer = optim.Adam(net.parameters(), lr=0.0001, amsgrad=False)\n#         scheduler = optim.lr_scheduler.StepLR(optimizer,step_size=1, gamma=0.5)\n        scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min', factor=0.5, patience=2, verbose=True, eps=1e-6)\n\n        \n        \n        lst_train_qwk = np.zeros(num_epochs)\n        lst_valid_qwk = np.zeros(num_epochs)   \n        \n        start = time.time()\n        best_qwk = -np.inf\n        for epoch in range(num_epochs):\n            running_loss = 0.0\n            \n            print('learning rate: %f' % optimizer.param_groups[0]['lr'])\n            \n#             add a get_accuracy function\n            \n            net.train()\n            optimizer.zero_grad() \n            predictions = []\n            truth_labels = []\n            for i, data in enumerate(tqdm(trainloader)):\n                inputs, labels = data[0].to(device),data[1].to(device)\n                optimizer.zero_grad() \n                outputs = net(inputs)\n                loss = criterion(outputs, labels)\n                loss.backward() #backward() is an attribute of the tensor class\n                optimizer.step()\n                running_loss += loss.item()\n                \n                outputs = outputs.detach().to('cpu').numpy().argmax(1)\n                labels = labels.detach().to('cpu').numpy()\n                predictions.append(outputs)\n                truth_labels.append(labels)\n                \n                \n\n                if i % 20 == 19:    # print every 20 mini-batches\n                    print('[%d, %5d] loss: %.3f' %\n                          (epoch + 1, i + 1, running_loss / 20))\n                    running_loss = 0.0\n            \n            qwk = cohen_kappa_score(predictions[0], truth_labels[0], weights='quadratic')\n            print('Current training QWK: %s' % qwk)\n            \n            running_loss = 0.0\n            predictions = []\n            truth_labels = []\n            net.eval()\n            for i, data in enumerate(tqdm(validloader)):\n                inputs, labels = data[0].to(device),data[1].to(device) \n                with torch.no_grad():\n                    outputs_predicted = net(inputs)\n                loss = criterion(outputs_predicted, labels)\n                running_loss += loss.item()\n                \n                \n#                 print(outputs_predicted)\n                outputs_predicted = outputs_predicted.to('cpu').numpy().argmax(1)\n#                 print(outputs_predicted)\n                labels = labels.to('cpu').numpy()\n                \n                predictions.append(outputs_predicted)\n                truth_labels.append(labels)\n#             print(predictions)\n#             print(truth_labels)\n            qwk = cohen_kappa_score(predictions[0], truth_labels[0], weights='quadratic') \n            \n\n            if qwk > best_qwk:\n                best_qwk = qwk\n                print('Saving Best Score ------------->')\n                PATH = 'foldnum%s'% fold_num + 'se-resnext50-32x4d.pth'\n                torch.save(net.state_dict(), PATH)\n                \n            scheduler.step(running_loss)\n            print('Current valid QWK: %s' % qwk)\n        \n        \n        print('Best QWK: %s' % best_qwk)\n        print('[%d] loss: %.3f' %\n              (epoch + 1, running_loss / 100))\n\n\n        print('Finished Fold Training')\n        end = time.time()\n        print('Minutes run for: %s' % ((end - start)/60))\n        return None","execution_count":13,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for fold in range(2):\n    training_(fold,num_epochs = 6)","execution_count":14,"outputs":[{"output_type":"stream","text":"Fold number 0:\nlearning rate: 0.000100\n","name":"stdout"},{"output_type":"display_data","data":{"text/plain":"HBox(children=(FloatProgress(value=0.0, max=332.0), HTML(value='')))","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6d0d7e06b3e740699ae0008de1830d19"}},"metadata":{}},{"output_type":"stream","text":"[1,    20] loss: 1.635\n[1,    40] loss: 1.456\n[1,    60] loss: 1.317\n[1,    80] loss: 1.397\n[1,   100] loss: 1.374\n[1,   120] loss: 1.249\n[1,   140] loss: 1.275\n[1,   160] loss: 1.305\n[1,   180] loss: 1.254\n[1,   200] loss: 1.297\n[1,   220] loss: 1.104\n[1,   240] loss: 1.204\n[1,   260] loss: 1.283\n[1,   280] loss: 1.248\n[1,   300] loss: 1.220\n[1,   320] loss: 1.200\n\nCurrent training QWK: -0.11524163568773238\n","name":"stdout"},{"output_type":"display_data","data":{"text/plain":"HBox(children=(FloatProgress(value=0.0, max=332.0), HTML(value='')))","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5481dd5ebd5641ccb6206ee810cfe000"}},"metadata":{}},{"output_type":"stream","text":"\nSaving Best Score ------------->\nCurrent valid QWK: 0.8009331259720063\nlearning rate: 0.000100\n","name":"stdout"},{"output_type":"display_data","data":{"text/plain":"HBox(children=(FloatProgress(value=0.0, max=332.0), HTML(value='')))","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ef6074444f09438c9160070a864b00c6"}},"metadata":{}},{"output_type":"stream","text":"[2,    20] loss: 1.116\n[2,    40] loss: 1.119\n[2,    60] loss: 0.997\n[2,    80] loss: 1.069\n[2,   100] loss: 1.068\n[2,   120] loss: 0.988\n[2,   140] loss: 0.993\n[2,   160] loss: 1.003\n[2,   180] loss: 1.040\n[2,   200] loss: 1.047\n[2,   220] loss: 0.890\n[2,   240] loss: 0.980\n[2,   260] loss: 1.034\n[2,   280] loss: 0.996\n[2,   300] loss: 1.010\n[2,   320] loss: 1.019\n\nCurrent training QWK: 0.8320209973753281\n","name":"stdout"},{"output_type":"display_data","data":{"text/plain":"HBox(children=(FloatProgress(value=0.0, max=332.0), HTML(value='')))","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"211bc63875ac4312a3aa6a88b392d033"}},"metadata":{}},{"output_type":"stream","text":"\nSaving Best Score ------------->\nCurrent valid QWK: 0.8713450292397661\nlearning rate: 0.000100\n","name":"stdout"},{"output_type":"display_data","data":{"text/plain":"HBox(children=(FloatProgress(value=0.0, max=332.0), HTML(value='')))","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7096f9b4ccc74e34b2ced537d06ce7b3"}},"metadata":{}},{"output_type":"stream","text":"[3,    20] loss: 0.958\n[3,    40] loss: 0.913\n[3,    60] loss: 0.759\n[3,    80] loss: 0.821\n[3,   100] loss: 0.891\n[3,   120] loss: 0.776\n[3,   140] loss: 0.733\n[3,   160] loss: 0.841\n[3,   180] loss: 0.792\n[3,   200] loss: 0.865\n[3,   220] loss: 0.713\n[3,   240] loss: 0.765\n[3,   260] loss: 0.776\n[3,   280] loss: 0.882\n[3,   300] loss: 0.806\n[3,   320] loss: 0.788\n\nCurrent training QWK: 0.875\n","name":"stdout"},{"output_type":"display_data","data":{"text/plain":"HBox(children=(FloatProgress(value=0.0, max=332.0), HTML(value='')))","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"267573737c884f589d6bf74ce6096ec1"}},"metadata":{}},{"output_type":"stream","text":"\nCurrent valid QWK: 0.817629179331307\nlearning rate: 0.000100\n","name":"stdout"},{"output_type":"display_data","data":{"text/plain":"HBox(children=(FloatProgress(value=0.0, max=332.0), HTML(value='')))","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6b9a3dac83044039a41c077355f92611"}},"metadata":{}},{"output_type":"stream","text":"[4,    20] loss: 0.746\n[4,    40] loss: 0.674\n[4,    60] loss: 0.594\n[4,    80] loss: 0.655\n[4,   100] loss: 0.673\n[4,   120] loss: 0.626\n[4,   140] loss: 0.538\n[4,   160] loss: 0.558\n[4,   180] loss: 0.647\n[4,   200] loss: 0.664\n[4,   220] loss: 0.523\n[4,   240] loss: 0.587\n[4,   260] loss: 0.600\n[4,   280] loss: 0.601\n[4,   300] loss: 0.603\n[4,   320] loss: 0.636\n\nCurrent training QWK: 0.86\n","name":"stdout"},{"output_type":"display_data","data":{"text/plain":"HBox(children=(FloatProgress(value=0.0, max=332.0), HTML(value='')))","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"65f96d8b66ba4780880c38a12b734b18"}},"metadata":{}},{"output_type":"stream","text":"\nEpoch     4: reducing learning rate of group 0 to 5.0000e-05.\nCurrent valid QWK: 0.79050736497545\nlearning rate: 0.000050\n","name":"stdout"},{"output_type":"display_data","data":{"text/plain":"HBox(children=(FloatProgress(value=0.0, max=332.0), HTML(value='')))","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"65f0479cb0eb43b890485a4ea186906f"}},"metadata":{}},{"output_type":"stream","text":"[5,    20] loss: 0.503\n[5,    40] loss: 0.442\n[5,    60] loss: 0.420\n[5,    80] loss: 0.396\n[5,   100] loss: 0.415\n[5,   120] loss: 0.381\n[5,   140] loss: 0.343\n[5,   160] loss: 0.373\n[5,   180] loss: 0.355\n[5,   200] loss: 0.379\n[5,   220] loss: 0.303\n[5,   240] loss: 0.328\n[5,   260] loss: 0.289\n[5,   280] loss: 0.286\n[5,   300] loss: 0.301\n[5,   320] loss: 0.257\n\nCurrent training QWK: 1.0\n","name":"stdout"},{"output_type":"display_data","data":{"text/plain":"HBox(children=(FloatProgress(value=0.0, max=332.0), HTML(value='')))","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f594f97c993e48f595c0b9fa4ff4bc1d"}},"metadata":{}},{"output_type":"stream","text":"\nCurrent valid QWK: 0.7605633802816901\nlearning rate: 0.000050\n","name":"stdout"},{"output_type":"display_data","data":{"text/plain":"HBox(children=(FloatProgress(value=0.0, max=332.0), HTML(value='')))","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"aaf76548a49944e4bca71d0c6c2404ee"}},"metadata":{}},{"output_type":"stream","text":"[6,    20] loss: 0.271\n[6,    40] loss: 0.241\n[6,    60] loss: 0.219\n[6,    80] loss: 0.245\n[6,   100] loss: 0.266\n[6,   120] loss: 0.221\n[6,   140] loss: 0.225\n[6,   160] loss: 0.230\n[6,   180] loss: 0.208\n[6,   200] loss: 0.208\n[6,   220] loss: 0.174\n[6,   240] loss: 0.184\n[6,   260] loss: 0.214\n[6,   280] loss: 0.194\n[6,   300] loss: 0.156\n[6,   320] loss: 0.145\n\nCurrent training QWK: 1.0\n","name":"stdout"},{"output_type":"display_data","data":{"text/plain":"HBox(children=(FloatProgress(value=0.0, max=332.0), HTML(value='')))","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1afca3b1ecbb4f8da6472c9e3e5a17ff"}},"metadata":{}},{"output_type":"stream","text":"\nCurrent valid QWK: 0.7595993322203672\nBest QWK: 0.8713450292397661\n[6] loss: 5.122\nFinished Fold Training\nMinutes run for: 78.16483758290609\nFold number 1:\nlearning rate: 0.000100\n","name":"stdout"},{"output_type":"display_data","data":{"text/plain":"HBox(children=(FloatProgress(value=0.0, max=332.0), HTML(value='')))","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7805377321cf497481be5ccf9ee1c6a4"}},"metadata":{}},{"output_type":"stream","text":"[1,    20] loss: 1.614\n[1,    40] loss: 1.417\n[1,    60] loss: 1.294\n[1,    80] loss: 1.304\n[1,   100] loss: 1.331\n[1,   120] loss: 1.291\n[1,   140] loss: 1.260\n[1,   160] loss: 1.260\n[1,   180] loss: 1.267\n[1,   200] loss: 1.246\n[1,   220] loss: 1.137\n[1,   240] loss: 1.287\n[1,   260] loss: 1.311\n[1,   280] loss: 1.167\n[1,   300] loss: 1.211\n[1,   320] loss: 1.182\n\nCurrent training QWK: -0.31175836030204973\n","name":"stdout"},{"output_type":"display_data","data":{"text/plain":"HBox(children=(FloatProgress(value=0.0, max=332.0), HTML(value='')))","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6868d52c566c4b30832a191206687acc"}},"metadata":{}},{"output_type":"stream","text":"\nSaving Best Score ------------->\nCurrent valid QWK: 0.8691588785046729\nlearning rate: 0.000100\n","name":"stdout"},{"output_type":"display_data","data":{"text/plain":"HBox(children=(FloatProgress(value=0.0, max=332.0), HTML(value='')))","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c353389fac194d29bb90b9cb89f31f11"}},"metadata":{}},{"output_type":"stream","text":"[2,    20] loss: 1.118\n[2,    40] loss: 1.106\n[2,    60] loss: 1.008\n[2,    80] loss: 1.049\n[2,   100] loss: 1.111\n[2,   120] loss: 1.036\n[2,   140] loss: 1.012\n[2,   160] loss: 0.977\n[2,   180] loss: 1.020\n[2,   200] loss: 1.029\n[2,   220] loss: 0.898\n[2,   240] loss: 1.079\n[2,   260] loss: 1.113\n[2,   280] loss: 0.968\n[2,   300] loss: 1.002\n[2,   320] loss: 1.004\n\nCurrent training QWK: 0.5\n","name":"stdout"},{"output_type":"display_data","data":{"text/plain":"HBox(children=(FloatProgress(value=0.0, max=332.0), HTML(value='')))","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"095943ee11c746db8a525003df6b38a9"}},"metadata":{}},{"output_type":"stream","text":"\nSaving Best Score ------------->\nCurrent valid QWK: 0.9361702127659575\nlearning rate: 0.000100\n","name":"stdout"},{"output_type":"display_data","data":{"text/plain":"HBox(children=(FloatProgress(value=0.0, max=332.0), HTML(value='')))","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4a94acf4bc634971b3e186f3eff98876"}},"metadata":{}},{"output_type":"stream","text":"[3,    20] loss: 0.920\n[3,    40] loss: 0.931\n[3,    60] loss: 0.813\n[3,    80] loss: 0.831\n[3,   100] loss: 0.902\n[3,   120] loss: 0.813\n[3,   140] loss: 0.768\n[3,   160] loss: 0.777\n[3,   180] loss: 0.780\n[3,   200] loss: 0.805\n[3,   220] loss: 0.704\n[3,   240] loss: 0.875\n[3,   260] loss: 0.847\n[3,   280] loss: 0.803\n[3,   300] loss: 0.807\n[3,   320] loss: 0.789\n\nCurrent training QWK: 0.7984084880636605\n","name":"stdout"},{"output_type":"display_data","data":{"text/plain":"HBox(children=(FloatProgress(value=0.0, max=332.0), HTML(value='')))","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9d1e7e944d0a476cadc3687035a7a3ad"}},"metadata":{}},{"output_type":"stream","text":"\nCurrent valid QWK: 0.9123287671232877\nlearning rate: 0.000100\n","name":"stdout"},{"output_type":"display_data","data":{"text/plain":"HBox(children=(FloatProgress(value=0.0, max=332.0), HTML(value='')))","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"44b36f416c18431aa350d30720852470"}},"metadata":{}},{"output_type":"stream","text":"[4,    20] loss: 0.718\n[4,    40] loss: 0.745\n[4,    60] loss: 0.632\n[4,    80] loss: 0.668\n[4,   100] loss: 0.687\n[4,   120] loss: 0.644\n[4,   140] loss: 0.567\n[4,   160] loss: 0.546\n[4,   180] loss: 0.565\n[4,   200] loss: 0.514\n[4,   220] loss: 0.501\n[4,   240] loss: 0.696\n[4,   260] loss: 0.600\n[4,   280] loss: 0.599\n[4,   300] loss: 0.623\n[4,   320] loss: 0.593\n\nCurrent training QWK: 0.6941896024464832\n","name":"stdout"},{"output_type":"display_data","data":{"text/plain":"HBox(children=(FloatProgress(value=0.0, max=332.0), HTML(value='')))","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7b53bec74bbb49a689994e99836325a8"}},"metadata":{}},{"output_type":"stream","text":"\nCurrent valid QWK: 0.900497512437811\nlearning rate: 0.000100\n","name":"stdout"},{"output_type":"display_data","data":{"text/plain":"HBox(children=(FloatProgress(value=0.0, max=332.0), HTML(value='')))","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9948a9f3d6ac4797a13d9ede0038df41"}},"metadata":{}},{"output_type":"stream","text":"[5,    20] loss: 0.547\n[5,    40] loss: 0.547\n[5,    60] loss: 0.417\n[5,    80] loss: 0.542\n[5,   100] loss: 0.519\n[5,   120] loss: 0.461\n[5,   140] loss: 0.404\n[5,   160] loss: 0.366\n[5,   180] loss: 0.448\n[5,   200] loss: 0.480\n[5,   220] loss: 0.359\n[5,   240] loss: 0.432\n[5,   260] loss: 0.472\n[5,   280] loss: 0.408\n[5,   300] loss: 0.492\n[5,   320] loss: 0.430\n\nCurrent training QWK: 0.9883040935672515\n","name":"stdout"},{"output_type":"display_data","data":{"text/plain":"HBox(children=(FloatProgress(value=0.0, max=332.0), HTML(value='')))","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0c9b4e619f8c4012a29340f3ad72440b"}},"metadata":{}},{"output_type":"stream","text":"\nEpoch     5: reducing learning rate of group 0 to 5.0000e-05.\nCurrent valid QWK: 0.9322033898305084\nlearning rate: 0.000050\n","name":"stdout"},{"output_type":"display_data","data":{"text/plain":"HBox(children=(FloatProgress(value=0.0, max=332.0), HTML(value='')))","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1c49b77697b342db965c5b6e98423530"}},"metadata":{}},{"output_type":"stream","text":"[6,    20] loss: 0.456\n[6,    40] loss: 0.374\n[6,    60] loss: 0.295\n[6,    80] loss: 0.353\n[6,   100] loss: 0.310\n[6,   120] loss: 0.289\n[6,   140] loss: 0.239\n[6,   160] loss: 0.266\n[6,   180] loss: 0.253\n[6,   200] loss: 0.218\n[6,   220] loss: 0.206\n[6,   240] loss: 0.219\n[6,   260] loss: 0.248\n[6,   280] loss: 0.205\n[6,   300] loss: 0.183\n[6,   320] loss: 0.184\n\nCurrent training QWK: 1.0\n","name":"stdout"},{"output_type":"display_data","data":{"text/plain":"HBox(children=(FloatProgress(value=0.0, max=332.0), HTML(value='')))","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6058f37ec90341d2a683b1c3a8e6bde7"}},"metadata":{}},{"output_type":"stream","text":"\nCurrent valid QWK: 0.909967845659164\nBest QWK: 0.9361702127659575\n[6] loss: 4.757\nFinished Fold Training\nMinutes run for: 78.74552985429764\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}