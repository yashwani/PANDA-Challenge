{"cells":[{"metadata":{"_uuid":"87bf64b6-dd99-4cf0-bd68-bb4b6c49c069","_cell_guid":"f29ce300-9b66-434c-b9c8-2ffbf18b5b86","trusted":true},"cell_type":"code","source":"# %% [code]\n# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\n# for dirname, _, filenames in os.walk('/kaggle/input'):\n#     for filename in filenames:\n#         print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session\n\n# %% [markdown]\n# # Libraries\n\n# %% [code]\n#Imports\nfrom torch.utils.data import Dataset\nimport cv2\nimport openslide\nfrom sklearn.model_selection import StratifiedKFold\nfrom sklearn.metrics import cohen_kappa_score\nfrom tqdm.notebook import tqdm\nimport time\n\nimport torch\nimport torch.nn as nn\nimport torchvision.transforms as transforms\nimport torchvision\nimport torch.optim as optim\nfrom torch.utils.data import DataLoader, Dataset\n\nfrom albumentations import Compose, Normalize, HorizontalFlip, VerticalFlip\nfrom albumentations.pytorch import ToTensorV2\n\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\ndevice\n\n# %% [markdown]\n# # Load into Pandas\n\n# %% [code]\ntrain = pd.read_csv('/kaggle/input/prostate-cancer-grade-assessment/train.csv')\ntrain.head()\n\n# %% [markdown]\n# # Dataset\n\n# %% [code]\nclass TrainingDataset(Dataset):\n    def __init__ (self, df, labels, transform = None):\n        self.df = df\n        self.labels = labels\n        self.transform = transform\n        \n    def __len__ (self):\n        return len(self.df)\n    \n    def __getitem__(self, idx):\n        slide_identifier = self.df['image_id'].values[idx]\n        image_path = '/kaggle/input/prostate-cancer-grade-assessment/train_images/' + slide_identifier + '.tiff'\n        slide = openslide.OpenSlide(image_path)\n        image = slide.read_region((0,0), slide.level_count - 1, slide.level_dimensions[-1]) #using the smallest image, denoted by [-1] index\n        image = cv2.resize(np.asarray(image)[:,:,0:3], (256, 256)) #downsampling to 256x256, slice and remove A index\n        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n        \n        if self.transform:\n            transformed = self.transform(image = image)\n            image = transformed['image']\n        \n        label = self.labels[idx]\n        return image, label\n    \nclass TestingDataset(Dataset):\n    def __init__ (self, df, folder, transform = None):\n        self.df = df\n        self.folder = folder\n        self.transform = transform\n        \n    def __len__ (self):\n        return len(self.df)\n    \n    def __getitem__(self, idx):\n        slide_identifier = self.df['image_id'].values[idx]\n        image_path = '/kaggle/input/prostate-cancer-grade-assessment/' + self.folder + '/'+ slide_identifier + '.tiff'\n        slide = openslide.OpenSlide(image_path)\n        image = slide.read_region((0,0), slide.level_count - 1, slide.level_dimensions[-1]) #using the smallest image, denoted by [-1] index\n        image = cv2.resize(np.asarray(image)[:,:,0:3], (256, 256)) #downsampling to 256x256\n        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n        \n        if self.transform:\n            transformed = self.transform(image = image)\n            image = transformed['image']\n        \n\n        return image\n\n# %% [markdown]\n# # Transformations\n\n# %% [code]\ndef get_transform(dataset_type):\n    assert dataset_type in ('train', 'valid')\n    if dataset_type == 'train':\n\n        return Compose([\n            HorizontalFlip(p=0.5),\n            VerticalFlip(p=0.5),\n            Normalize(\n                mean=[0.485, 0.456, 0.406],\n                std=[0.229, 0.224, 0.225],\n            ),\n            ToTensorV2(),\n        ])\n    elif dataset_type == 'valid':\n\n        return Compose([\n            Normalize(\n                mean=[0.485, 0.456, 0.406],\n                std=[0.229, 0.224, 0.225],\n            ),\n            ToTensorV2(),\n        ])\n\n# %% [markdown]\n# # Split Dataset Into n (4) Folds\n\n# %% [code]\nfold_dataset = train.copy()\nkfold = StratifiedKFold(n_splits = 4, shuffle = True ,random_state = 42)\ngen = kfold.split(fold_dataset, fold_dataset['isup_grade']) #create generator\nfor fold, (train_,test_) in enumerate(gen): \n    fold_dataset.loc[test_, 'fold'] = fold #assign fold number to indices for test (1/4 of dataset)\nfold_dataset['fold'] = fold_dataset['fold'].astype(int) #change to integer\nfold_dataset.head()\n\n# %% [markdown]\n# # Build Model\n\n# %% [markdown]\n# **Resnet34**:\n# https://github.com/pytorch/vision/blob/master/torchvision/models/resnet.py\n# \n# \n# weights: https://download.pytorch.org/models/resnet34-333f7ec4.pth\n\n# %% [code]\ndef conv3x3(in_planes, out_planes, stride=1, groups=1, dilation=1):\n    \"\"\"3x3 convolution with padding\"\"\"\n    return nn.Conv2d(in_planes, out_planes, kernel_size=3, stride=stride,\n                     padding=dilation, groups=groups, bias=False, dilation=dilation)\n\n\ndef conv1x1(in_planes, out_planes, stride=1):\n    \"\"\"1x1 convolution\"\"\"\n    return nn.Conv2d(in_planes, out_planes, kernel_size=1, stride=stride, bias=False)\n\n\nclass BasicBlock(nn.Module):\n    expansion = 1\n\n    def __init__(self, inplanes, planes, stride=1, downsample=None, groups=1,\n                 base_width=64, dilation=1, norm_layer=None):\n        super(BasicBlock, self).__init__()\n        if norm_layer is None:\n            norm_layer = nn.BatchNorm2d\n        if groups != 1 or base_width != 64:\n            raise ValueError('BasicBlock only supports groups=1 and base_width=64')\n        if dilation > 1:\n            raise NotImplementedError(\"Dilation > 1 not supported in BasicBlock\")\n        # Both self.conv1 and self.downsample layers downsample the input when stride != 1\n        self.conv1 = conv3x3(inplanes, planes, stride)\n        self.bn1 = norm_layer(planes)\n        self.relu = nn.ReLU(inplace=True)\n        self.conv2 = conv3x3(planes, planes)\n        self.bn2 = norm_layer(planes)\n        self.downsample = downsample\n        self.stride = stride\n\n    def forward(self, x):\n        identity = x\n\n        out = self.conv1(x)\n        out = self.bn1(out)\n        out = self.relu(out)\n\n        out = self.conv2(out)\n        out = self.bn2(out)\n\n        if self.downsample is not None:\n            identity = self.downsample(x)\n\n        out += identity\n        out = self.relu(out)\n\n        return out\n\n\nclass Bottleneck(nn.Module):\n    # Bottleneck in torchvision places the stride for downsampling at 3x3 convolution(self.conv2)\n    # while original implementation places the stride at the first 1x1 convolution(self.conv1)\n    # according to \"Deep residual learning for image recognition\"https://arxiv.org/abs/1512.03385.\n    # This variant is also known as ResNet V1.5 and improves accuracy according to\n    # https://ngc.nvidia.com/catalog/model-scripts/nvidia:resnet_50_v1_5_for_pytorch.\n\n    expansion = 4\n\n    def __init__(self, inplanes, planes, stride=1, downsample=None, groups=1,\n                 base_width=64, dilation=1, norm_layer=None):\n        super(Bottleneck, self).__init__()\n        if norm_layer is None:\n            norm_layer = nn.BatchNorm2d\n        width = int(planes * (base_width / 64.)) * groups\n        # Both self.conv2 and self.downsample layers downsample the input when stride != 1\n        self.conv1 = conv1x1(inplanes, width)\n        self.bn1 = norm_layer(width)\n        self.conv2 = conv3x3(width, width, stride, groups, dilation)\n        self.bn2 = norm_layer(width)\n        self.conv3 = conv1x1(width, planes * self.expansion)\n        self.bn3 = norm_layer(planes * self.expansion)\n        self.relu = nn.ReLU(inplace=True)\n        self.downsample = downsample\n        self.stride = stride\n\n    def forward(self, x):\n        identity = x\n\n        out = self.conv1(x)\n        out = self.bn1(out)\n        out = self.relu(out)\n\n        out = self.conv2(out)\n        out = self.bn2(out)\n        out = self.relu(out)\n\n        out = self.conv3(out)\n        out = self.bn3(out)\n\n        if self.downsample is not None:\n            identity = self.downsample(x)\n\n        out += identity\n        out = self.relu(out)\n\n        return out\n\n\nclass ResNet(nn.Module):\n\n    def __init__(self, block, layers, num_classes=1000, zero_init_residual=False,\n                 groups=1, width_per_group=64, replace_stride_with_dilation=None,\n                 norm_layer=None):\n        super(ResNet, self).__init__()\n        if norm_layer is None:\n            norm_layer = nn.BatchNorm2d\n        self._norm_layer = norm_layer\n\n        self.inplanes = 64\n        self.dilation = 1\n        if replace_stride_with_dilation is None:\n            # each element in the tuple indicates if we should replace\n            # the 2x2 stride with a dilated convolution instead\n            replace_stride_with_dilation = [False, False, False]\n        if len(replace_stride_with_dilation) != 3:\n            raise ValueError(\"replace_stride_with_dilation should be None \"\n                             \"or a 3-element tuple, got {}\".format(replace_stride_with_dilation))\n        self.groups = groups\n        self.base_width = width_per_group\n        self.conv1 = nn.Conv2d(3, self.inplanes, kernel_size=7, stride=2, padding=3,\n                               bias=False)\n        self.bn1 = norm_layer(self.inplanes)\n        self.relu = nn.ReLU(inplace=True)\n        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n        self.layer1 = self._make_layer(block, 64, layers[0])\n        self.layer2 = self._make_layer(block, 128, layers[1], stride=2,\n                                       dilate=replace_stride_with_dilation[0])\n        self.layer3 = self._make_layer(block, 256, layers[2], stride=2,\n                                       dilate=replace_stride_with_dilation[1])\n        self.layer4 = self._make_layer(block, 512, layers[3], stride=2,\n                                       dilate=replace_stride_with_dilation[2])\n        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n        self.fc = nn.Linear(512 * block.expansion, num_classes)\n\n        for m in self.modules():\n            if isinstance(m, nn.Conv2d):\n                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n            elif isinstance(m, (nn.BatchNorm2d, nn.GroupNorm)):\n                nn.init.constant_(m.weight, 1)\n                nn.init.constant_(m.bias, 0)\n\n        # Zero-initialize the last BN in each residual branch,\n        # so that the residual branch starts with zeros, and each residual block behaves like an identity.\n        # This improves the model by 0.2~0.3% according to https://arxiv.org/abs/1706.02677\n        if zero_init_residual:\n            for m in self.modules():\n                if isinstance(m, Bottleneck):\n                    nn.init.constant_(m.bn3.weight, 0)\n                elif isinstance(m, BasicBlock):\n                    nn.init.constant_(m.bn2.weight, 0)\n\n    def _make_layer(self, block, planes, blocks, stride=1, dilate=False):\n        norm_layer = self._norm_layer\n        downsample = None\n        previous_dilation = self.dilation\n        if dilate:\n            self.dilation *= stride\n            stride = 1\n        if stride != 1 or self.inplanes != planes * block.expansion:\n            downsample = nn.Sequential(\n                conv1x1(self.inplanes, planes * block.expansion, stride),\n                norm_layer(planes * block.expansion),\n            )\n\n        layers = []\n        layers.append(block(self.inplanes, planes, stride, downsample, self.groups,\n                            self.base_width, previous_dilation, norm_layer))\n        self.inplanes = planes * block.expansion\n        for _ in range(1, blocks):\n            layers.append(block(self.inplanes, planes, groups=self.groups,\n                                base_width=self.base_width, dilation=self.dilation,\n                                norm_layer=norm_layer))\n\n        return nn.Sequential(*layers)\n\n    def _forward_impl(self, x):\n        # See note [TorchScript super()]\n        x = self.conv1(x)\n        x = self.bn1(x)\n        x = self.relu(x)\n        x = self.maxpool(x)\n\n        x = self.layer1(x)\n        x = self.layer2(x)\n        x = self.layer3(x)\n        x = self.layer4(x)\n\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.fc(x)\n\n        return x\n\n    def forward(self, x):\n        return self._forward_impl(x)\n\n\ndef _resnet(arch, block, layers, pretrained, progress, **kwargs):\n    model = ResNet(block, layers, **kwargs)\n    if pretrained:\n        state_dict = load_state_dict_from_url(model_urls[arch],\n                                              progress=progress)\n        model.load_state_dict(state_dict)\n    return model\n\n\ndef resnet18(pretrained=False, progress=True, **kwargs):\n    r\"\"\"ResNet-18 model from\n    `\"Deep Residual Learning for Image Recognition\" <https://arxiv.org/pdf/1512.03385.pdf>`_\n    Args:\n        pretrained (bool): If True, returns a model pre-trained on ImageNet\n        progress (bool): If True, displays a progress bar of the download to stderr\n    \"\"\"\n    return _resnet('resnet18', BasicBlock, [2, 2, 2, 2], pretrained, progress,\n                   **kwargs)\n\n\ndef resnet34(pretrained=False, progress=True, **kwargs):\n    r\"\"\"ResNet-34 model from\n    `\"Deep Residual Learning for Image Recognition\" <https://arxiv.org/pdf/1512.03385.pdf>`_\n    Args:\n        pretrained (bool): If True, returns a model pre-trained on ImageNet\n        progress (bool): If True, displays a progress bar of the download to stderr\n    \"\"\"\n    return _resnet('resnet34', BasicBlock, [3, 4, 6, 3], pretrained, progress,\n                   **kwargs)\n\n# %% [code]\nclass ResNet34(nn.Module):\n    def __init__(self, freeze = True):\n        super(ResNet34, self).__init__()\n#         layers = []\n#         layers.append(nn.Linear(512, 256))\n#         layers.append(nn.ReLU())\n#         layers.append(nn.Linear(256, 6))\n\n\n        self.model = resnet34(pretrained=False)\n        weights_path = '/kaggle/input/resnet34/resnet34.pth'\n        self.model.load_state_dict(torch.load(weights_path))\n        self.model.fc = nn.Linear(self.model.fc.in_features, 6)\n#         self.model.avg_pool = nn.AdaptiveAvgPool2d(1)\n#         self.model.last_linear = nn.Linear(self.model.last_linear.in_features, CFG.target_size)\n        \n    def forward(self, x):\n        x = self.model(x)\n        return x\n\n# %% [code]\nnet = ResNet34()\nnet\n\n# %% [code]\n# class ResNet34(nn.Module):\n#     def __init__(self, pretrained, freeze = True):\n#         super(ResNet34, self).__init__()\n#         if pretrained:\n#             self.model = pretrainedmodels.__dict__['resnet34'](pretrained = 'imagenet')\n#         else:\n#             self.model = pretrainedmodels.__dict__['resnet34'](pretrained = None)\n#         if freeze:\n#             for param in self.model.parameters():\n#                 param.requires_grad = False\n#         layers = []\n#         layers.append(nn.Linear(512, 256))\n#         layers.append(nn.ReLU())\n#         layers.append(nn.Linear(256, 6))\n\n\n#         self.l0 = nn.Sequential(*layers)\n#         self.l1 = nn.Sequential(*layers)\n\n#     def forward(self, X):\n#         bs, _, _, _ = X.shape\n#         X = self.model.features(X)\n#         X = nn.functional.adaptive_avg_pool2d(X, 1).reshape(bs, -1)\n#         l0 = self.l0(X)\n#         l1 = self.l1(X)\n#         return l0, l1\n\n# %% [markdown]\n# # Train Model\n\n# %% [code]\n# ## For Debugging Purposes:\n# fold_dataset = fold_dataset.sample(100)\n\n# %% [code]\n#  def training_(fold_num, num_epochs):\n        \n#         # get the dataset from fold_dataset for current fold #################################################################\n#         print('Fold number %s:' % fold_num)\n        \n#         train_df = fold_dataset.loc[fold_dataset['fold'] != fold_num].reset_index(drop = True)\n#         valid_df = fold_dataset.loc[fold_dataset['fold'] == fold_num].reset_index(drop = True)\n        \n#         train_label = train_df['isup_grade']\n#         valid_label = valid_df['isup_grade']\n        \n#         train_dataset = TrainingDataset(train_df, train_label, get_transform(dataset_type = 'train'))\n#         valid_dataset = TrainingDataset(valid_df, valid_label, get_transform(dataset_type = 'valid'))\n        \n#         trainloader = DataLoader(train_dataset, batch_size = 16)\n#         validloader = DataLoader(valid_dataset, batch_size = 16)\n        \n#         # initialize model, and set criterion, optimizer, scheduler #################################################################\n# #         net = VGG('VGG16', dropout_rate = 0)\n#         net = ResNet34(freeze = False)\n#         net.to(device)\n#         criterion = nn.CrossEntropyLoss()\n#         criterion.to(device)\n# #         optimizer = optim.SGD(net.parameters(), lr = 0.1, momentum = 0.9, weight_decay=5e-4)\n#         optimizer = optim.Adam(net.parameters(), lr=0.0001, amsgrad=False)\n#         scheduler = optim.lr_scheduler.StepLR(optimizer,step_size=1, gamma=0.5)\n# #         scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min', factor=0.5, patience=2, verbose=True, eps=1e-6)\n\n        \n        \n#         lst_train_qwk = np.zeros(num_epochs)\n#         lst_valid_qwk = np.zeros(num_epochs)   \n        \n#         start = time.time()\n#         best_qwk = -np.inf\n#         for epoch in range(num_epochs):\n#             running_loss = 0.0\n            \n#             print('learning rate: %f' % optimizer.param_groups[0]['lr'])\n            \n# #             add a get_accuracy function\n            \n#             net.train()\n#             optimizer.zero_grad() \n#             for i, data in enumerate(tqdm(trainloader)):\n#                 inputs, labels = data[0].to(device),data[1].to(device)\n#                 optimizer.zero_grad() \n#                 outputs = net(inputs)\n#                 loss = criterion(outputs, labels)\n#                 loss.backward() #backward() is an attribute of the tensor class\n#                 optimizer.step()\n#                 running_loss += loss.item()\n\n\n\n#                 if i % 20 == 19:    # print every 20 mini-batches\n#                     print('[%d, %5d] loss: %.3f' %\n#                           (epoch + 1, i + 1, running_loss / 20))\n#                     running_loss = 0.0\n#             running_loss = 0.0\n            \n#             predictions = []\n#             truth_labels = []\n#             net.eval()\n#             for i, data in enumerate(tqdm(validloader)):\n#                 inputs, labels = data[0].to(device),data[1].to(device) \n#                 with torch.no_grad():\n#                     outputs_predicted = net(inputs)\n#                 loss = criterion(outputs_predicted, labels)\n#                 running_loss += loss.item()\n                \n                \n# #                 print(outputs_predicted)\n#                 outputs_predicted = outputs_predicted.to('cpu').numpy().argmax(1)\n# #                 print(outputs_predicted)\n#                 labels = labels.to('cpu').numpy()\n                \n#                 predictions.append(outputs_predicted)\n#                 truth_labels.append(labels)\n# #             print(predictions)\n# #             print(truth_labels)\n#             qwk = cohen_kappa_score(predictions[0], truth_labels[0], weights='quadratic') \n            \n\n#             if qwk > best_qwk:\n#                 best_qwk = qwk\n#                 print('Saving Best Score ------------->')\n#                 PATH = 'foldnum%s'% fold_num + 'ResNet34.pth'\n#                 torch.save(net.state_dict(), PATH)\n                \n#             scheduler.step()\n#             print('Current QWK: %s' % qwk)\n        \n        \n#         print('Best QWK: %s' % best_qwk)\n#         print('[%d] loss: %.3f' %\n#               (epoch + 1, running_loss / 100))\n\n\n#         print('Finished Fold Training')\n#         end = time.time()\n#         print('Minutes run for: %s' % ((end - start)/60))\n#         return None\n\n# %% [code]\n# for fold in range(4):\n#     training_(fold,num_epochs = 8)\n\n# %% [markdown]\n# # Train Without Cross Validation\n\n# %% [code]\nfold_dataset = train.copy()\nkfold = StratifiedKFold(n_splits = 10, shuffle = True ,random_state = 42)\ngen = kfold.split(fold_dataset, fold_dataset['isup_grade']) #create generator\nfor fold, (train_,test_) in enumerate(gen): \n    fold_dataset.loc[test_, 'fold'] = fold #assign fold number to indices for test (1/4 of dataset)\nfold_dataset['fold'] = fold_dataset['fold'].astype(int) #change to integer\nfold_dataset.head()\n\n# %% [code]\n def training_(fold_num, num_epochs):\n        \n        # get the dataset from fold_dataset for current fold #################################################################\n        print('Fold number %s:' % fold_num)\n        \n        train_df = fold_dataset.loc[fold_dataset['fold'] != fold_num].reset_index(drop = True)\n        valid_df = fold_dataset.loc[fold_dataset['fold'] == fold_num].reset_index(drop = True)\n        \n        train_label = train_df['isup_grade']\n        valid_label = valid_df['isup_grade']\n        \n        train_dataset = TrainingDataset(train_df, train_label, get_transform(dataset_type = 'train'))\n        valid_dataset = TrainingDataset(valid_df, valid_label, get_transform(dataset_type = 'valid'))\n        \n        trainloader = DataLoader(train_dataset, batch_size = 16)\n        validloader = DataLoader(valid_dataset, batch_size = 16)\n        \n        # initialize model, and set criterion, optimizer, scheduler #################################################################\n#         net = VGG('VGG16', dropout_rate = 0)\n        net = ResNet34(freeze = False)\n        net.to(device)\n        criterion = nn.CrossEntropyLoss()\n        criterion.to(device)\n#         optimizer = optim.SGD(net.parameters(), lr = 0.1, momentum = 0.9, weight_decay=5e-4)\n        optimizer = optim.Adam(net.parameters(), lr=0.0001, amsgrad=False)\n#         scheduler = optim.lr_scheduler.StepLR(optimizer,step_size=1, gamma=0.5)\n        scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min', factor=0.5, patience=2, verbose=True, eps=1e-6)\n\n        \n        \n        lst_train_qwk = np.zeros(num_epochs)\n        lst_valid_qwk = np.zeros(num_epochs)   \n        \n        start = time.time()\n        best_qwk = -np.inf\n        for epoch in range(num_epochs):\n            running_loss = 0.0\n            \n            print('learning rate: %f' % optimizer.param_groups[0]['lr'])\n            \n#             add a get_accuracy function\n            \n            net.train()\n            optimizer.zero_grad() \n            for i, data in enumerate(tqdm(trainloader)):\n                inputs, labels = data[0].to(device),data[1].to(device)\n                optimizer.zero_grad() \n                outputs = net(inputs)\n                loss = criterion(outputs, labels)\n                loss.backward() #backward() is an attribute of the tensor class\n                optimizer.step()\n                running_loss += loss.item()\n\n\n\n                if i % 20 == 19:    # print every 20 mini-batches\n                    print('[%d, %5d] loss: %.3f' %\n                          (epoch + 1, i + 1, running_loss / 20))\n                    running_loss = 0.0\n            \n            running_loss = 0.0\n            predictions = []\n            truth_labels = []\n            net.eval()\n            for i, data in enumerate(tqdm(validloader)):\n                inputs, labels = data[0].to(device),data[1].to(device) \n                with torch.no_grad():\n                    outputs_predicted = net(inputs)\n                loss = criterion(outputs_predicted, labels)\n                running_loss += loss.item()\n                \n                \n#                 print(outputs_predicted)\n                outputs_predicted = outputs_predicted.to('cpu').numpy().argmax(1)\n#                 print(outputs_predicted)\n                labels = labels.to('cpu').numpy()\n                \n                predictions.append(outputs_predicted)\n                truth_labels.append(labels)\n#             print(predictions)\n#             print(truth_labels)\n            qwk = cohen_kappa_score(predictions[0], truth_labels[0], weights='quadratic') \n            \n\n            if qwk > best_qwk:\n                best_qwk = qwk\n                print('Saving Best Score ------------->')\n                PATH = 'foldnum%s'% fold_num + 'ResNet34.pth'\n                torch.save(net.state_dict(), PATH)\n                \n            scheduler.step(running_loss)\n            print('Current QWK: %s' % qwk)\n        \n        \n        print('Best QWK: %s' % best_qwk)\n        print('[%d] loss: %.3f' %\n              (epoch + 1, running_loss / 100))\n\n\n        print('Finished Fold Training')\n        end = time.time()\n        print('Minutes run for: %s' % ((end - start)/60))\n        return None\n\n# %% [code]\nfold = 7 #pick first fold\ntraining_(fold,num_epochs = 10)\n\n# %% [markdown]\n# # Inference and Submission\n\n# %% [code]\n# def predict_test(net, dataloader):\n#     predicted_mat = []\n#     net.to(device)\n#     for i, images in enumerate(tqdm(dataloader)):\n#         images = images.to(device)\n#         with torch.no_grad():\n#             predicted = net(images)\n#         predicted = predicted[0].to('cpu')\n#         predicted = predicted.numpy()\n#         predicted_mat.append(predicted)\n#     return predicted_mat\n\n# %% [code]\n# def submit(test_df, image_folder = 'test_images'):\n#     if os.path.exists('/kaggle/input/prostate-cancer-grade-assessment/' + image_folder):\n#         print('Running inference ---------->')\n#         test_dataset = TestingDataset(test_df, image_folder, get_transform(dataset_type = 'valid'))\n#         testloader = DataLoader(test_dataset, batch_size = 16, shuffle = False)\n#         probs = []\n#         for fold_num in range(4):\n#             PATH = 'foldnum%s'% fold_num + 'ResNet34.pth'\n#             net = ResNet34(pretrained = False, freeze = False)\n#             net.load_state_dict(torch.load(PATH, map_location = device)) #might need to be changed\n#             predicted = predict_test(net, testloader)\n#             probs.append(predicted)\n#         probs_avg = np.mean(probs,0)\n#         predictions = probs_avg[0].transpose().argmax(0)\n#         test_df['isup_grade'] = predictions\n# #         test_df.insert(len(test_df.columns), 'isup_grade', predictions, allow_duplicates=True) #adds to last column\n#     else:\n#         print('directory not found')\n#     return test_df\n\n# %% [code]\n# sampledf = pd.read_csv('/kaggle/input/prostate-cancer-grade-assessment/sample_submission.csv')\n# submission = submit(sampledf, image_folder = 'test_images')\n# submission['isup_grade'] = submission['isup_grade'].astype(int)\n# submission.to_csv('submission.csv', index=False)\n# submission.head()\n\n# %% [code]\n\n\n# %% [code]\n","execution_count":0,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}